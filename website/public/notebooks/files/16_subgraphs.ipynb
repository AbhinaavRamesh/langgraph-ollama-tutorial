{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 16: Subgraph Patterns\n",
    "\n",
    "In this tutorial, you'll learn to build **composable, reusable graph components** using subgraphs.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Wrapping subgraphs as nodes in parent graphs\n",
    "- State transformation between parent and subgraph\n",
    "- Creating reusable graph components\n",
    "- Chaining, conditional, and parallel subgraph patterns\n",
    "- Building modular agent systems\n",
    "\n",
    "By the end, you'll be able to compose complex workflows from simple, tested building blocks.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Tutorials 14-15 (Multi-Agent Patterns)\n",
    "- Understanding of StateGraph and state management\n",
    "- Familiarity with TypedDict and type transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Subgraphs?\n",
    "\n",
    "As agent systems grow, you need:\n",
    "\n",
    "1. **Reusability**: Use the same RAG pipeline in multiple agents\n",
    "2. **Encapsulation**: Hide internal complexity behind clean interfaces\n",
    "3. **Testing**: Test components independently before composing\n",
    "4. **Modularity**: Swap implementations without changing the parent graph\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                      Parent Graph                          │\n",
    "│                                                             │\n",
    "│  ┌─────────┐    ┌─────────────────────────┐    ┌─────────┐ │\n",
    "│  │  Entry  │───▶│      Subgraph           │───▶│  Next   │ │\n",
    "│  │  Node   │    │  (Black Box)            │    │  Node   │ │\n",
    "│  └─────────┘    └─────────────────────────┘    └─────────┘ │\n",
    "│                           │                                 │\n",
    "│              State In ────┴──── State Out                   │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "The key insight: **subgraphs can have different state schemas** than the parent graph. State transformation functions bridge the gap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_ollama_local import LocalAgentConfig\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "config = LocalAgentConfig()\n",
    "llm = ChatOllama(\n",
    "    model=config.ollama.model,\n",
    "    base_url=config.ollama.base_url,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(f\"Model: {config.ollama.model}\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create a Simple Subgraph\n",
    "\n",
    "Let's create a simple summarization subgraph that we'll embed in a larger system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "# Subgraph has its own state schema\n",
    "class SummaryState(TypedDict):\n",
    "    \"\"\"State for the summarization subgraph.\"\"\"\n",
    "    text: str\n",
    "    summary: str\n",
    "    word_count: int\n",
    "\n",
    "\n",
    "def summarize_node(state: SummaryState) -> dict:\n",
    "    \"\"\"Summarize the input text.\"\"\"\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=\"Summarize the following text in 2-3 sentences.\"),\n",
    "        HumanMessage(content=state[\"text\"]),\n",
    "    ])\n",
    "    summary = response.content\n",
    "    return {\n",
    "        \"summary\": summary,\n",
    "        \"word_count\": len(summary.split()),\n",
    "    }\n",
    "\n",
    "\n",
    "# Build the subgraph\n",
    "summary_workflow = StateGraph(SummaryState)\n",
    "summary_workflow.add_node(\"summarize\", summarize_node)\n",
    "summary_workflow.add_edge(START, \"summarize\")\n",
    "summary_workflow.add_edge(\"summarize\", END)\n",
    "\n",
    "summary_graph = summary_workflow.compile()\n",
    "\n",
    "print(\"Summary subgraph created!\")\n",
    "\n",
    "# Test it standalone\n",
    "result = summary_graph.invoke({\n",
    "    \"text\": \"Python is a high-level programming language known for its simplicity and readability. It supports multiple programming paradigms including procedural, object-oriented, and functional programming. Python has a large standard library and active community.\",\n",
    "    \"summary\": \"\",\n",
    "    \"word_count\": 0,\n",
    "})\n",
    "\n",
    "print(f\"\\nSummary: {result['summary']}\")\n",
    "print(f\"Word count: {result['word_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a Parent Graph with Different State\n",
    "\n",
    "Our parent graph has a different state schema. We need to transform between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent graph has a different state schema\n",
    "class DocumentState(TypedDict):\n",
    "    \"\"\"State for document processing.\"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "    document_content: str\n",
    "    document_summary: str\n",
    "    processed: bool\n",
    "\n",
    "\n",
    "print(\"Parent state schema:\")\n",
    "print(\"  - messages: conversation history\")\n",
    "print(\"  - document_content: the raw document\")\n",
    "print(\"  - document_summary: will hold the summary\")\n",
    "print(\"  - processed: flag when complete\")\n",
    "print(\"\\nSubgraph state schema:\")\n",
    "print(\"  - text: input text\")\n",
    "print(\"  - summary: output summary\")\n",
    "print(\"  - word_count: summary length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define State Transformation Functions\n",
    "\n",
    "The key to subgraph composition: **state_in** and **state_out** functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_state_in(parent_state: DocumentState) -> SummaryState:\n",
    "    \"\"\"\n",
    "    Transform parent state to subgraph input.\n",
    "    \n",
    "    Maps: document_content -> text\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"text\": parent_state[\"document_content\"],\n",
    "        \"summary\": \"\",\n",
    "        \"word_count\": 0,\n",
    "    }\n",
    "\n",
    "\n",
    "def summary_state_out(subgraph_state: SummaryState, parent_state: DocumentState) -> dict:\n",
    "    \"\"\"\n",
    "    Transform subgraph output to parent state updates.\n",
    "    \n",
    "    Maps: summary -> document_summary\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"document_summary\": subgraph_state[\"summary\"],\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"State transformers defined!\")\n",
    "print(\"\\nstate_in: DocumentState -> SummaryState\")\n",
    "print(\"state_out: SummaryState -> dict (parent updates)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Wrap Subgraph as Node\n",
    "\n",
    "Now we create a node function that wraps the subgraph with state transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subgraph_node(subgraph, state_in, state_out):\n",
    "    \"\"\"\n",
    "    Wrap a subgraph as a node in parent graph.\n",
    "    \n",
    "    Args:\n",
    "        subgraph: Compiled subgraph\n",
    "        state_in: Transform parent state to subgraph input\n",
    "        state_out: Transform subgraph output to parent updates\n",
    "    \n",
    "    Returns:\n",
    "        Node function for parent graph\n",
    "    \"\"\"\n",
    "    def node(state):\n",
    "        # Transform state\n",
    "        subgraph_input = state_in(state)\n",
    "        \n",
    "        # Run subgraph\n",
    "        subgraph_output = subgraph.invoke(subgraph_input)\n",
    "        \n",
    "        # Transform output\n",
    "        return state_out(subgraph_output, state)\n",
    "    \n",
    "    return node\n",
    "\n",
    "\n",
    "# Create the wrapped node\n",
    "summary_node = create_subgraph_node(\n",
    "    summary_graph,\n",
    "    summary_state_in,\n",
    "    summary_state_out,\n",
    ")\n",
    "\n",
    "print(\"Subgraph wrapped as node!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Build Parent Graph with Embedded Subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "def validate_node(state: DocumentState) -> dict:\n",
    "    \"\"\"Validate document has content.\"\"\"\n",
    "    if not state.get(\"document_content\"):\n",
    "        return {\"messages\": [AIMessage(content=\"No document provided.\")]}\n",
    "    return {\"messages\": [AIMessage(content=\"Document validated.\")]}\n",
    "\n",
    "\n",
    "def finalize_node(state: DocumentState) -> dict:\n",
    "    \"\"\"Mark processing complete.\"\"\"\n",
    "    return {\n",
    "        \"processed\": True,\n",
    "        \"messages\": [AIMessage(content=f\"Summary complete: {state['document_summary'][:100]}...\")],\n",
    "    }\n",
    "\n",
    "\n",
    "# Build parent graph\n",
    "parent_workflow = StateGraph(DocumentState)\n",
    "\n",
    "# Add nodes\n",
    "parent_workflow.add_node(\"validate\", validate_node)\n",
    "parent_workflow.add_node(\"summarize\", summary_node)  # Our wrapped subgraph!\n",
    "parent_workflow.add_node(\"finalize\", finalize_node)\n",
    "\n",
    "# Add edges\n",
    "parent_workflow.add_edge(START, \"validate\")\n",
    "parent_workflow.add_edge(\"validate\", \"summarize\")\n",
    "parent_workflow.add_edge(\"summarize\", \"finalize\")\n",
    "parent_workflow.add_edge(\"finalize\", END)\n",
    "\n",
    "parent_graph = parent_workflow.compile()\n",
    "\n",
    "print(\"Parent graph with embedded subgraph compiled!\")\n",
    "print(\"\\nFlow: validate -> summarize (subgraph) -> finalize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Run the Composed System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"Machine learning is a subset of artificial intelligence that enables \n",
    "systems to learn and improve from experience without being explicitly programmed. \n",
    "It focuses on developing algorithms that can access data and use it to learn for \n",
    "themselves. The process begins with observations or data, such as examples, direct \n",
    "experience, or instruction, to look for patterns in data and make better decisions \n",
    "in the future. The primary aim is to allow computers to learn automatically without \n",
    "human intervention and adjust actions accordingly.\"\"\"\n",
    "\n",
    "result = parent_graph.invoke({\n",
    "    \"messages\": [],\n",
    "    \"document_content\": document,\n",
    "    \"document_summary\": \"\",\n",
    "    \"processed\": False,\n",
    "})\n",
    "\n",
    "print(\"Result:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Processed: {result['processed']}\")\n",
    "print(f\"\\nSummary:\\n{result['document_summary']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Using the Built-in Module\n",
    "\n",
    "The `langgraph_ollama_local.patterns.subgraphs` module provides these utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_ollama_local.patterns.subgraphs import (\n",
    "    create_subgraph_node,\n",
    "    field_mapper_in,\n",
    "    field_mapper_out,\n",
    ")\n",
    "\n",
    "# Use field mappers for simple transformations\n",
    "state_in = field_mapper_in(\n",
    "    (\"document_content\", \"text\"),  # parent_field -> subgraph_field\n",
    ")\n",
    "\n",
    "state_out = field_mapper_out(\n",
    "    (\"summary\", \"document_summary\"),  # subgraph_field -> parent_field\n",
    ")\n",
    "\n",
    "# Create node with module function\n",
    "summary_node_v2 = create_subgraph_node(summary_graph, state_in, state_out)\n",
    "\n",
    "print(\"Using module utilities!\")\n",
    "print(\"field_mapper_in: creates state_in from field mappings\")\n",
    "print(\"field_mapper_out: creates state_out from field mappings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Chaining Multiple Subgraphs\n",
    "\n",
    "You can chain subgraphs for sequential processing pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another subgraph: sentiment analysis\n",
    "class SentimentState(TypedDict):\n",
    "    text: str\n",
    "    sentiment: str\n",
    "    confidence: float\n",
    "\n",
    "\n",
    "def sentiment_node(state: SentimentState) -> dict:\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=\"Analyze the sentiment. Respond with: POSITIVE, NEGATIVE, or NEUTRAL\"),\n",
    "        HumanMessage(content=state[\"text\"]),\n",
    "    ])\n",
    "    sentiment = response.content.strip().upper()\n",
    "    if \"POSITIVE\" in sentiment:\n",
    "        return {\"sentiment\": \"POSITIVE\", \"confidence\": 0.8}\n",
    "    elif \"NEGATIVE\" in sentiment:\n",
    "        return {\"sentiment\": \"NEGATIVE\", \"confidence\": 0.8}\n",
    "    return {\"sentiment\": \"NEUTRAL\", \"confidence\": 0.6}\n",
    "\n",
    "\n",
    "sentiment_workflow = StateGraph(SentimentState)\n",
    "sentiment_workflow.add_node(\"analyze\", sentiment_node)\n",
    "sentiment_workflow.add_edge(START, \"analyze\")\n",
    "sentiment_workflow.add_edge(\"analyze\", END)\n",
    "sentiment_graph = sentiment_workflow.compile()\n",
    "\n",
    "print(\"Sentiment subgraph created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_ollama_local.patterns.subgraphs import chain_subgraphs\n",
    "\n",
    "# Extended parent state\n",
    "class FullAnalysisState(TypedDict):\n",
    "    document_content: str\n",
    "    document_summary: str\n",
    "    document_sentiment: str\n",
    "\n",
    "\n",
    "# Chain: summarize then analyze sentiment\n",
    "chained_node = chain_subgraphs([\n",
    "    (\n",
    "        summary_graph,\n",
    "        lambda s: {\"text\": s[\"document_content\"], \"summary\": \"\", \"word_count\": 0},\n",
    "        lambda out, s: {\"document_summary\": out[\"summary\"]},\n",
    "    ),\n",
    "    (\n",
    "        sentiment_graph,\n",
    "        lambda s: {\"text\": s.get(\"document_summary\", s[\"document_content\"]), \"sentiment\": \"\", \"confidence\": 0},\n",
    "        lambda out, s: {\"document_sentiment\": out[\"sentiment\"]},\n",
    "    ),\n",
    "])\n",
    "\n",
    "# Build graph with chained subgraphs\n",
    "analysis_workflow = StateGraph(FullAnalysisState)\n",
    "analysis_workflow.add_node(\"analyze\", chained_node)\n",
    "analysis_workflow.add_edge(START, \"analyze\")\n",
    "analysis_workflow.add_edge(\"analyze\", END)\n",
    "analysis_graph = analysis_workflow.compile()\n",
    "\n",
    "# Test\n",
    "result = analysis_graph.invoke({\n",
    "    \"document_content\": \"I absolutely love this product! It exceeded all my expectations and works perfectly.\",\n",
    "    \"document_summary\": \"\",\n",
    "    \"document_sentiment\": \"\",\n",
    "})\n",
    "\n",
    "print(f\"Summary: {result['document_summary']}\")\n",
    "print(f\"Sentiment: {result['document_sentiment']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Conditional Subgraphs\n",
    "\n",
    "Run different subgraphs based on conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_ollama_local.patterns.subgraphs import conditional_subgraph\n",
    "\n",
    "# Create a \"short summary\" subgraph\n",
    "def short_summary_node(state):\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=\"Summarize in exactly one sentence.\"),\n",
    "        HumanMessage(content=state[\"text\"]),\n",
    "    ])\n",
    "    return {\"summary\": response.content, \"word_count\": len(response.content.split())}\n",
    "\n",
    "short_workflow = StateGraph(SummaryState)\n",
    "short_workflow.add_node(\"summarize\", short_summary_node)\n",
    "short_workflow.add_edge(START, \"summarize\")\n",
    "short_workflow.add_edge(\"summarize\", END)\n",
    "short_graph = short_workflow.compile()\n",
    "\n",
    "\n",
    "# Condition: use short summary for texts under 100 words\n",
    "def is_short_text(state):\n",
    "    text = state.get(\"document_content\", \"\")\n",
    "    return len(text.split()) < 100\n",
    "\n",
    "\n",
    "# Conditional node\n",
    "conditional_summary_node = conditional_subgraph(\n",
    "    is_short_text,\n",
    "    # True: use short summary\n",
    "    (short_graph, summary_state_in, summary_state_out),\n",
    "    # False: use full summary\n",
    "    (summary_graph, summary_state_in, summary_state_out),\n",
    ")\n",
    "\n",
    "print(\"Conditional subgraph node created!\")\n",
    "print(\"Short texts (<100 words) -> one-sentence summary\")\n",
    "print(\"Long texts (>=100 words) -> full summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Complete Subgraph Patterns Implementation ===\n",
    "\n",
    "from typing import Annotated, Callable\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langgraph_ollama_local import LocalAgentConfig\n",
    "\n",
    "\n",
    "# === Subgraph Node Wrapper ===\n",
    "def create_subgraph_node(subgraph, state_in, state_out):\n",
    "    \"\"\"Wrap subgraph as parent graph node.\"\"\"\n",
    "    def node(state):\n",
    "        sub_input = state_in(state)\n",
    "        sub_output = subgraph.invoke(sub_input)\n",
    "        return state_out(sub_output, state)\n",
    "    return node\n",
    "\n",
    "\n",
    "# === Field Mappers ===\n",
    "def field_mapper_in(*mappings):\n",
    "    \"\"\"Create state_in from (parent_field, sub_field) mappings.\"\"\"\n",
    "    def state_in(parent):\n",
    "        return {sub: parent.get(par, \"\") for par, sub in mappings}\n",
    "    return state_in\n",
    "\n",
    "def field_mapper_out(*mappings):\n",
    "    \"\"\"Create state_out from (sub_field, parent_field) mappings.\"\"\"\n",
    "    def state_out(sub, parent):\n",
    "        return {par: sub.get(sf, \"\") for sf, par in mappings}\n",
    "    return state_out\n",
    "\n",
    "\n",
    "# === Chain Subgraphs ===\n",
    "def chain_subgraphs(subgraphs):\n",
    "    \"\"\"Chain (subgraph, state_in, state_out) tuples.\"\"\"\n",
    "    def chained(state):\n",
    "        current = state.copy()\n",
    "        for sg, sin, sout in subgraphs:\n",
    "            out = sg.invoke(sin(current))\n",
    "            current.update(sout(out, current))\n",
    "        return {k: v for k, v in current.items() if k not in state or state[k] != v}\n",
    "    return chained\n",
    "\n",
    "\n",
    "# === Conditional Subgraph ===\n",
    "def conditional_subgraph(condition, true_sg, false_sg=None):\n",
    "    \"\"\"Run subgraph based on condition.\"\"\"\n",
    "    def conditional(state):\n",
    "        if condition(state):\n",
    "            sg, sin, sout = true_sg\n",
    "        elif false_sg:\n",
    "            sg, sin, sout = false_sg\n",
    "        else:\n",
    "            return {}\n",
    "        return sout(sg.invoke(sin(state)), state)\n",
    "    return conditional\n",
    "\n",
    "\n",
    "# === Example Usage ===\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = LocalAgentConfig()\n",
    "    llm = ChatOllama(model=cfg.ollama.model, base_url=cfg.ollama.base_url, temperature=0)\n",
    "    \n",
    "    # Create subgraph\n",
    "    class SubState(TypedDict):\n",
    "        text: str\n",
    "        result: str\n",
    "    \n",
    "    def process(state):\n",
    "        r = llm.invoke([SystemMessage(content=\"Summarize:\"), HumanMessage(content=state[\"text\"])])\n",
    "        return {\"result\": r.content}\n",
    "    \n",
    "    sub = StateGraph(SubState)\n",
    "    sub.add_node(\"process\", process)\n",
    "    sub.add_edge(START, \"process\")\n",
    "    sub.add_edge(\"process\", END)\n",
    "    subgraph = sub.compile()\n",
    "    \n",
    "    # Create parent with subgraph\n",
    "    class ParentState(TypedDict):\n",
    "        input_text: str\n",
    "        output_summary: str\n",
    "    \n",
    "    node = create_subgraph_node(\n",
    "        subgraph,\n",
    "        field_mapper_in((\"input_text\", \"text\")),\n",
    "        field_mapper_out((\"result\", \"output_summary\")),\n",
    "    )\n",
    "    \n",
    "    parent = StateGraph(ParentState)\n",
    "    parent.add_node(\"summarize\", node)\n",
    "    parent.add_edge(START, \"summarize\")\n",
    "    parent.add_edge(\"summarize\", END)\n",
    "    graph = parent.compile()\n",
    "    \n",
    "    result = graph.invoke({\"input_text\": \"Python is great for ML.\", \"output_summary\": \"\"})\n",
    "    print(result[\"output_summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Subgraph** | Complete, compiled graph used as component |\n",
    "| **State Transformation** | Functions to convert between state schemas |\n",
    "| **state_in** | Parent state → Subgraph input |\n",
    "| **state_out** | Subgraph output → Parent state updates |\n",
    "| **Field Mappers** | Simple transformation for field renaming |\n",
    "| **Chain** | Sequential subgraph execution |\n",
    "| **Conditional** | Choose subgraph based on state |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to Use Subgraphs\n",
    "\n",
    "| Use Subgraphs When | Don't Use When |\n",
    "|-------------------|----------------|\n",
    "| Reusing logic across graphs | Single-use logic |\n",
    "| Different state schemas needed | Same state schema |\n",
    "| Testing components independently | Tightly coupled logic |\n",
    "| Swapping implementations | Fixed implementation |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned the core patterns for building modular, composable LangGraph systems:\n",
    "\n",
    "1. **Multi-Agent Collaboration** (Tutorial 14): Supervisor coordinates specialists\n",
    "2. **Hierarchical Teams** (Tutorial 15): Nested team structures\n",
    "3. **Subgraph Patterns** (Tutorial 16): Composable, reusable components\n",
    "\n",
    "These patterns can be combined to build sophisticated agent systems that are maintainable, testable, and scalable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
