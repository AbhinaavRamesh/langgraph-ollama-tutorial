{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 15: Hierarchical Agent Teams\n",
    "\n",
    "In this tutorial, you'll build **nested agent teams** where team supervisors coordinate sub-teams of specialists.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Creating team subgraphs with their own supervisors\n",
    "- Building a top-level supervisor that coordinates teams\n",
    "- State transformation between hierarchical and team states\n",
    "- Aggregating results from multiple teams\n",
    "- When to use hierarchical vs flat multi-agent structures\n",
    "\n",
    "By the end, you'll have a hierarchical system with a research team and development team, each with their own members and supervisor.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Tutorial 14 (Multi-Agent Collaboration)\n",
    "- Understanding of the supervisor pattern\n",
    "- Familiarity with StateGraph and conditional edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Hierarchical Teams?\n",
    "\n",
    "The flat supervisor pattern works well for small teams (3-5 agents). But for larger, more complex tasks:\n",
    "\n",
    "1. **Specialization by domain**: Research team vs Development team vs QA team\n",
    "2. **Reduced cognitive load**: Each supervisor manages fewer direct reports\n",
    "3. **Parallel work**: Teams can work independently on their domains\n",
    "4. **Scalability**: Add new teams without changing the top-level structure\n",
    "\n",
    "```\n",
    "                     ┌─────────────────┐\n",
    "                     │   Top-Level     │\n",
    "                     │   Supervisor    │\n",
    "                     └────────┬────────┘\n",
    "                              │\n",
    "          ┌───────────────────┴───────────────────┐\n",
    "          │                                       │\n",
    "          ▼                                       ▼\n",
    "   ┌─────────────────┐                     ┌─────────────────┐\n",
    "   │  Research Team  │                     │  Development    │\n",
    "   │    Supervisor   │                     │  Team Supervisor│\n",
    "   └────────┬────────┘                     └────────┬────────┘\n",
    "            │                                       │\n",
    "    ┌───────┴───────┐                       ┌───────┴───────┐\n",
    "    │               │                       │               │\n",
    "    ▼               ▼                       ▼               ▼\n",
    "┌─────────┐   ┌─────────┐             ┌─────────┐   ┌─────────┐\n",
    "│ Searcher│   │ Analyst │             │ Coder   │   │ Tester  │\n",
    "└─────────┘   └─────────┘             └─────────┘   └─────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_ollama_local import LocalAgentConfig\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "config = LocalAgentConfig()\n",
    "llm = ChatOllama(\n",
    "    model=config.ollama.model,\n",
    "    base_url=config.ollama.base_url,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(f\"Using model: {config.ollama.model}\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Team and Hierarchical States\n",
    "\n",
    "We need two state types:\n",
    "1. **TeamState**: For individual teams and their members\n",
    "2. **HierarchicalState**: For the top-level coordination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "import operator\n",
    "\n",
    "\n",
    "class TeamState(TypedDict):\n",
    "    \"\"\"State for a single team.\"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "    task: str\n",
    "    team_name: str\n",
    "    next_member: str\n",
    "    member_outputs: Annotated[list[dict], operator.add]\n",
    "    iteration: int\n",
    "    max_iterations: int\n",
    "    team_result: str\n",
    "\n",
    "\n",
    "class HierarchicalState(TypedDict):\n",
    "    \"\"\"State for hierarchical coordination.\"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "    task: str\n",
    "    active_team: str\n",
    "    team_results: dict[str, str]  # team_name -> result\n",
    "    iteration: int\n",
    "    max_iterations: int\n",
    "    final_result: str\n",
    "\n",
    "\n",
    "print(\"States defined!\")\n",
    "print(\"\\nTeamState: For individual team work\")\n",
    "print(\"HierarchicalState: For top-level coordination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Team Building Functions\n",
    "\n",
    "Each team is a complete subgraph with its own supervisor and members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "def create_team_supervisor(llm, team_name: str, member_names: list[str]):\n",
    "    \"\"\"Create a team supervisor node.\"\"\"\n",
    "    \n",
    "    class TeamDecision(BaseModel):\n",
    "        next_member: str = Field(description=\"Member name or 'DONE'\")\n",
    "        reasoning: str\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(TeamDecision)\n",
    "    members_list = \", \".join(member_names)\n",
    "    \n",
    "    def supervisor(state: TeamState) -> dict:\n",
    "        outputs = state.get(\"member_outputs\", [])\n",
    "        progress = \"\\n\".join([\n",
    "            f\"{o['member']}: {o['output'][:200]}...\" for o in outputs\n",
    "        ]) or \"No work yet.\"\n",
    "        \n",
    "        decision = structured_llm.invoke([\n",
    "            SystemMessage(content=f\"\"\"You supervise the {team_name} team.\n",
    "Members: {members_list}\n",
    "Decide who works next, or say DONE when team task is complete.\"\"\"),\n",
    "            HumanMessage(content=f\"Task: {state['task']}\\nProgress: {progress}\")\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            \"next_member\": decision.next_member,\n",
    "            \"iteration\": state[\"iteration\"] + 1,\n",
    "        }\n",
    "    \n",
    "    return supervisor\n",
    "\n",
    "\n",
    "def create_team_member(llm, member_name: str, role_prompt: str):\n",
    "    \"\"\"Create a team member node.\"\"\"\n",
    "    \n",
    "    def member(state: TeamState) -> dict:\n",
    "        response = llm.invoke([\n",
    "            SystemMessage(content=role_prompt),\n",
    "            HumanMessage(content=f\"Team task: {state['task']}\")\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            \"member_outputs\": [{\n",
    "                \"member\": member_name,\n",
    "                \"output\": response.content\n",
    "            }]\n",
    "        }\n",
    "    \n",
    "    return member\n",
    "\n",
    "\n",
    "def create_team_finalize(team_name: str):\n",
    "    \"\"\"Create team finalization node.\"\"\"\n",
    "    \n",
    "    def finalize(state: TeamState) -> dict:\n",
    "        outputs = state.get(\"member_outputs\", [])\n",
    "        result = \"\\n\\n\".join([\n",
    "            f\"### {o['member']}\\n{o['output']}\" for o in outputs\n",
    "        ])\n",
    "        return {\"team_result\": f\"## {team_name} Team\\n\\n{result}\"}\n",
    "    \n",
    "    return finalize\n",
    "\n",
    "\n",
    "print(\"Team building functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build a Team Graph\n",
    "\n",
    "Let's create a reusable function to build complete team graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_team_graph(llm, team_name: str, members: list[tuple[str, str]]):\n",
    "    \"\"\"\n",
    "    Build a complete team graph.\n",
    "    \n",
    "    Args:\n",
    "        llm: Language model\n",
    "        team_name: Name of the team\n",
    "        members: List of (member_name, role_prompt) tuples\n",
    "    \n",
    "    Returns:\n",
    "        Compiled team graph\n",
    "    \"\"\"\n",
    "    member_names = [name for name, _ in members]\n",
    "    \n",
    "    workflow = StateGraph(TeamState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"supervisor\", create_team_supervisor(llm, team_name, member_names))\n",
    "    for name, prompt in members:\n",
    "        workflow.add_node(name, create_team_member(llm, name, prompt))\n",
    "    workflow.add_node(\"finalize\", create_team_finalize(team_name))\n",
    "    \n",
    "    # Entry\n",
    "    workflow.add_edge(START, \"supervisor\")\n",
    "    \n",
    "    # Routing\n",
    "    def route(state):\n",
    "        if state[\"iteration\"] >= state[\"max_iterations\"]:\n",
    "            return \"finalize\"\n",
    "        if state[\"next_member\"] == \"DONE\":\n",
    "            return \"finalize\"\n",
    "        if state[\"next_member\"] in member_names:\n",
    "            return state[\"next_member\"]\n",
    "        return \"finalize\"\n",
    "    \n",
    "    routing_map = {name: name for name in member_names}\n",
    "    routing_map[\"finalize\"] = \"finalize\"\n",
    "    \n",
    "    workflow.add_conditional_edges(\"supervisor\", route, routing_map)\n",
    "    \n",
    "    # Members return to supervisor\n",
    "    for name, _ in members:\n",
    "        workflow.add_edge(name, \"supervisor\")\n",
    "    \n",
    "    workflow.add_edge(\"finalize\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "print(\"Team graph builder defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Specific Teams\n",
    "\n",
    "Now let's create our Research and Development teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research Team\n",
    "research_team = build_team_graph(\n",
    "    llm,\n",
    "    \"Research\",\n",
    "    members=[\n",
    "        (\"searcher\", \"You search for information and best practices. Be thorough.\"),\n",
    "        (\"analyst\", \"You analyze findings and identify key insights. Be concise.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Development Team\n",
    "dev_team = build_team_graph(\n",
    "    llm,\n",
    "    \"Development\",\n",
    "    members=[\n",
    "        (\"coder\", \"You write clean, well-documented code. Follow best practices.\"),\n",
    "        (\"tester\", \"You write tests and identify edge cases. Be thorough.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Teams created!\")\n",
    "print(\"- Research Team: searcher, analyst\")\n",
    "print(\"- Development Team: coder, tester\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test a Team Independently\n",
    "\n",
    "Each team can work independently before we connect them hierarchically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the research team\n",
    "research_result = research_team.invoke({\n",
    "    \"messages\": [],\n",
    "    \"task\": \"Research best practices for input validation in Python\",\n",
    "    \"team_name\": \"Research\",\n",
    "    \"next_member\": \"\",\n",
    "    \"member_outputs\": [],\n",
    "    \"iteration\": 0,\n",
    "    \"max_iterations\": 4,\n",
    "    \"team_result\": \"\",\n",
    "})\n",
    "\n",
    "print(\"Research Team Result:\")\n",
    "print(\"=\"*50)\n",
    "print(research_result[\"team_result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create the Top-Level Supervisor\n",
    "\n",
    "The top supervisor coordinates between teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_top_supervisor(llm, team_names: list[str]):\n",
    "    \"\"\"Create top-level supervisor.\"\"\"\n",
    "    \n",
    "    class TopDecision(BaseModel):\n",
    "        next_team: str = Field(description=\"Team name or 'FINISH'\")\n",
    "        reasoning: str\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(TopDecision)\n",
    "    teams_list = \", \".join(team_names)\n",
    "    \n",
    "    def supervisor(state: HierarchicalState) -> dict:\n",
    "        results = state.get(\"team_results\", {})\n",
    "        progress = \"\\n\".join([\n",
    "            f\"{team}: {result[:200]}...\" for team, result in results.items()\n",
    "        ]) or \"No teams have reported yet.\"\n",
    "        \n",
    "        decision = structured_llm.invoke([\n",
    "            SystemMessage(content=f\"\"\"You coordinate teams: {teams_list}\n",
    "Assign work to the right team. Say FINISH when overall task is complete.\n",
    "Typically: research first, then development.\"\"\"),\n",
    "            HumanMessage(content=f\"Task: {state['task']}\\nTeam progress: {progress}\")\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            \"active_team\": decision.next_team,\n",
    "            \"iteration\": state[\"iteration\"] + 1,\n",
    "        }\n",
    "    \n",
    "    return supervisor\n",
    "\n",
    "\n",
    "print(\"Top supervisor creator defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create Team Wrappers\n",
    "\n",
    "We need to wrap team graphs as nodes that transform state correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_team_wrapper(team_graph, team_name: str):\n",
    "    \"\"\"Wrap a team graph as a node in the hierarchical graph.\"\"\"\n",
    "    \n",
    "    def team_node(state: HierarchicalState) -> dict:\n",
    "        # Transform to team state\n",
    "        team_input = {\n",
    "            \"messages\": [],\n",
    "            \"task\": state[\"task\"],\n",
    "            \"team_name\": team_name,\n",
    "            \"next_member\": \"\",\n",
    "            \"member_outputs\": [],\n",
    "            \"iteration\": 0,\n",
    "            \"max_iterations\": 4,\n",
    "            \"team_result\": \"\",\n",
    "        }\n",
    "        \n",
    "        # Run team\n",
    "        team_output = team_graph.invoke(team_input)\n",
    "        \n",
    "        # Update hierarchical state\n",
    "        new_results = state.get(\"team_results\", {}).copy()\n",
    "        new_results[team_name] = team_output.get(\"team_result\", \"\")\n",
    "        \n",
    "        return {\"team_results\": new_results}\n",
    "    \n",
    "    return team_node\n",
    "\n",
    "\n",
    "def create_aggregate():\n",
    "    \"\"\"Create aggregation node.\"\"\"\n",
    "    \n",
    "    def aggregate(state: HierarchicalState) -> dict:\n",
    "        results = state.get(\"team_results\", {})\n",
    "        final = \"\\n\\n---\\n\\n\".join([\n",
    "            f\"# {team}\\n\\n{result}\" for team, result in results.items()\n",
    "        ])\n",
    "        return {\"final_result\": final}\n",
    "    \n",
    "    return aggregate\n",
    "\n",
    "\n",
    "print(\"Team wrapper and aggregation defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Build the Hierarchical Graph\n",
    "\n",
    "Now we connect everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our teams\n",
    "teams = {\n",
    "    \"research\": research_team,\n",
    "    \"development\": dev_team,\n",
    "}\n",
    "\n",
    "team_names = list(teams.keys())\n",
    "\n",
    "# Build hierarchical graph\n",
    "hierarchical = StateGraph(HierarchicalState)\n",
    "\n",
    "# Add top supervisor\n",
    "hierarchical.add_node(\"top_supervisor\", create_top_supervisor(llm, team_names))\n",
    "\n",
    "# Add team nodes\n",
    "for name, graph in teams.items():\n",
    "    hierarchical.add_node(name, create_team_wrapper(graph, name))\n",
    "\n",
    "# Add aggregate\n",
    "hierarchical.add_node(\"aggregate\", create_aggregate())\n",
    "\n",
    "# Entry\n",
    "hierarchical.add_edge(START, \"top_supervisor\")\n",
    "\n",
    "# Routing\n",
    "def route_top(state):\n",
    "    if state[\"iteration\"] >= state[\"max_iterations\"]:\n",
    "        return \"aggregate\"\n",
    "    if state[\"active_team\"] == \"FINISH\":\n",
    "        return \"aggregate\"\n",
    "    if state[\"active_team\"].lower() in team_names:\n",
    "        return state[\"active_team\"].lower()\n",
    "    return \"aggregate\"\n",
    "\n",
    "routing_map = {name: name for name in team_names}\n",
    "routing_map[\"aggregate\"] = \"aggregate\"\n",
    "\n",
    "hierarchical.add_conditional_edges(\"top_supervisor\", route_top, routing_map)\n",
    "\n",
    "# Teams return to top supervisor\n",
    "for name in team_names:\n",
    "    hierarchical.add_edge(name, \"top_supervisor\")\n",
    "\n",
    "hierarchical.add_edge(\"aggregate\", END)\n",
    "\n",
    "# Compile\n",
    "hierarchical_graph = hierarchical.compile()\n",
    "\n",
    "print(\"Hierarchical graph compiled!\")\n",
    "print(\"\\nStructure:\")\n",
    "print(\"  top_supervisor -> [research | development | aggregate]\")\n",
    "print(\"  research (team) -> top_supervisor\")\n",
    "print(\"  development (team) -> top_supervisor\")\n",
    "print(\"  aggregate -> END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Run the Hierarchical System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hierarchical_task(task: str, max_iterations: int = 6):\n",
    "    \"\"\"Run a task through the hierarchical system.\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"Task: {task}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = hierarchical_graph.invoke({\n",
    "        \"messages\": [],\n",
    "        \"task\": task,\n",
    "        \"active_team\": \"\",\n",
    "        \"team_results\": {},\n",
    "        \"iteration\": 0,\n",
    "        \"max_iterations\": max_iterations,\n",
    "        \"final_result\": \"\",\n",
    "    })\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL RESULT\")\n",
    "    print(\"=\"*60)\n",
    "    print(result[\"final_result\"])\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Test with a full task\n",
    "result = run_hierarchical_task(\n",
    "    \"Create a Python function to validate and sanitize user email input\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Using the Built-in Module\n",
    "\n",
    "The `langgraph_ollama_local.agents.hierarchical` module provides these patterns ready to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_ollama_local.agents.hierarchical import (\n",
    "    create_team_graph,\n",
    "    create_hierarchical_graph,\n",
    "    run_hierarchical_task as run_task,\n",
    ")\n",
    "\n",
    "# Create teams using the module\n",
    "research = create_team_graph(\n",
    "    llm, \"research\",\n",
    "    members=[\n",
    "        (\"searcher\", \"Search for information and solutions.\", None),\n",
    "        (\"analyst\", \"Analyze findings and provide insights.\", None),\n",
    "    ]\n",
    ")\n",
    "\n",
    "development = create_team_graph(\n",
    "    llm, \"development\",\n",
    "    members=[\n",
    "        (\"coder\", \"Write clean, documented code.\", None),\n",
    "        (\"tester\", \"Write tests and check edge cases.\", None),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create hierarchical graph\n",
    "graph = create_hierarchical_graph(\n",
    "    llm,\n",
    "    {\"research\": research, \"development\": development}\n",
    ")\n",
    "\n",
    "# Run a task\n",
    "result = run_task(graph, \"Build a password strength checker\", max_iterations=5)\n",
    "print(result[\"final_result\"][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Complete Hierarchical Teams Implementation ===\n",
    "\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "import operator\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langgraph_ollama_local import LocalAgentConfig\n",
    "\n",
    "\n",
    "# === States ===\n",
    "class TeamState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    task: str\n",
    "    team_name: str\n",
    "    next_member: str\n",
    "    member_outputs: Annotated[list[dict], operator.add]\n",
    "    iteration: int\n",
    "    max_iterations: int\n",
    "    team_result: str\n",
    "\n",
    "class HierarchicalState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    task: str\n",
    "    active_team: str\n",
    "    team_results: dict[str, str]\n",
    "    iteration: int\n",
    "    max_iterations: int\n",
    "    final_result: str\n",
    "\n",
    "\n",
    "# === Team Builder ===\n",
    "def build_team(llm, name: str, members: list[tuple[str, str]]):\n",
    "    member_names = [n for n, _ in members]\n",
    "    \n",
    "    class Decision(BaseModel):\n",
    "        next_member: str\n",
    "        reasoning: str\n",
    "    \n",
    "    def supervisor(state):\n",
    "        decision = llm.with_structured_output(Decision).invoke([\n",
    "            SystemMessage(content=f\"Supervise {name} team: {member_names}. Say DONE when finished.\"),\n",
    "            HumanMessage(content=f\"Task: {state['task']}\")\n",
    "        ])\n",
    "        return {\"next_member\": decision.next_member, \"iteration\": state[\"iteration\"] + 1}\n",
    "    \n",
    "    def make_member(n, prompt):\n",
    "        def member(state):\n",
    "            r = llm.invoke([SystemMessage(content=prompt), HumanMessage(content=state[\"task\"])])\n",
    "            return {\"member_outputs\": [{\"member\": n, \"output\": r.content}]}\n",
    "        return member\n",
    "    \n",
    "    def finalize(state):\n",
    "        return {\"team_result\": \"\\n\".join([o[\"output\"] for o in state.get(\"member_outputs\", [])])}\n",
    "    \n",
    "    def route(state):\n",
    "        if state[\"iteration\"] >= state[\"max_iterations\"] or state[\"next_member\"] == \"DONE\":\n",
    "            return \"finalize\"\n",
    "        return state[\"next_member\"] if state[\"next_member\"] in member_names else \"finalize\"\n",
    "    \n",
    "    g = StateGraph(TeamState)\n",
    "    g.add_node(\"supervisor\", supervisor)\n",
    "    for n, p in members:\n",
    "        g.add_node(n, make_member(n, p))\n",
    "    g.add_node(\"finalize\", finalize)\n",
    "    g.add_edge(START, \"supervisor\")\n",
    "    g.add_conditional_edges(\"supervisor\", route, {n: n for n in member_names} | {\"finalize\": \"finalize\"})\n",
    "    for n, _ in members:\n",
    "        g.add_edge(n, \"supervisor\")\n",
    "    g.add_edge(\"finalize\", END)\n",
    "    return g.compile()\n",
    "\n",
    "\n",
    "# === Hierarchical Builder ===\n",
    "def build_hierarchical(llm, teams: dict):\n",
    "    names = list(teams.keys())\n",
    "    \n",
    "    class Decision(BaseModel):\n",
    "        next_team: str\n",
    "        reasoning: str\n",
    "    \n",
    "    def top_supervisor(state):\n",
    "        decision = llm.with_structured_output(Decision).invoke([\n",
    "            SystemMessage(content=f\"Coordinate teams: {names}. Say FINISH when done.\"),\n",
    "            HumanMessage(content=f\"Task: {state['task']}\")\n",
    "        ])\n",
    "        return {\"active_team\": decision.next_team, \"iteration\": state[\"iteration\"] + 1}\n",
    "    \n",
    "    def wrap_team(graph, name):\n",
    "        def node(state):\n",
    "            out = graph.invoke({\"messages\": [], \"task\": state[\"task\"], \"team_name\": name,\n",
    "                \"next_member\": \"\", \"member_outputs\": [], \"iteration\": 0, \"max_iterations\": 4, \"team_result\": \"\"})\n",
    "            new = state.get(\"team_results\", {}).copy()\n",
    "            new[name] = out.get(\"team_result\", \"\")\n",
    "            return {\"team_results\": new}\n",
    "        return node\n",
    "    \n",
    "    def aggregate(state):\n",
    "        return {\"final_result\": \"\\n\\n\".join([f\"# {k}\\n{v}\" for k, v in state.get(\"team_results\", {}).items()])}\n",
    "    \n",
    "    def route(state):\n",
    "        if state[\"iteration\"] >= state[\"max_iterations\"] or state[\"active_team\"] == \"FINISH\":\n",
    "            return \"aggregate\"\n",
    "        return state[\"active_team\"].lower() if state[\"active_team\"].lower() in names else \"aggregate\"\n",
    "    \n",
    "    g = StateGraph(HierarchicalState)\n",
    "    g.add_node(\"top_supervisor\", top_supervisor)\n",
    "    for name, graph in teams.items():\n",
    "        g.add_node(name, wrap_team(graph, name))\n",
    "    g.add_node(\"aggregate\", aggregate)\n",
    "    g.add_edge(START, \"top_supervisor\")\n",
    "    g.add_conditional_edges(\"top_supervisor\", route, {n: n for n in names} | {\"aggregate\": \"aggregate\"})\n",
    "    for name in names:\n",
    "        g.add_edge(name, \"top_supervisor\")\n",
    "    g.add_edge(\"aggregate\", END)\n",
    "    return g.compile()\n",
    "\n",
    "\n",
    "# === Use ===\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = LocalAgentConfig()\n",
    "    llm = ChatOllama(model=cfg.ollama.model, base_url=cfg.ollama.base_url, temperature=0)\n",
    "    \n",
    "    teams = {\n",
    "        \"research\": build_team(llm, \"research\", [(\"searcher\", \"Search info\"), (\"analyst\", \"Analyze\")]),\n",
    "        \"dev\": build_team(llm, \"dev\", [(\"coder\", \"Write code\"), (\"tester\", \"Test code\")]),\n",
    "    }\n",
    "    \n",
    "    graph = build_hierarchical(llm, teams)\n",
    "    result = graph.invoke({\"messages\": [], \"task\": \"Build a URL validator\",\n",
    "        \"active_team\": \"\", \"team_results\": {}, \"iteration\": 0, \"max_iterations\": 5, \"final_result\": \"\"})\n",
    "    print(result[\"final_result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Team Subgraphs** | Each team is a complete graph with supervisor and members |\n",
    "| **Top Supervisor** | Coordinates between teams at the highest level |\n",
    "| **State Transformation** | Convert between hierarchical and team states |\n",
    "| **Team Wrappers** | Wrap team graphs as nodes in parent graph |\n",
    "| **Result Aggregation** | Combine all team outputs at the end |\n",
    "| **Nested Iteration** | Each level has its own iteration limits |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to Use Hierarchical vs Flat\n",
    "\n",
    "| Use Hierarchical When | Use Flat When |\n",
    "|----------------------|---------------|\n",
    "| Many agents (6+) | Few agents (3-5) |\n",
    "| Clear domain boundaries | Agents collaborate closely |\n",
    "| Teams can work independently | Work is highly sequential |\n",
    "| Need organizational structure | Simple task decomposition |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next\n",
    "\n",
    "- [Tutorial 16: Subgraph Patterns](16_subgraphs.ipynb) - Composable, reusable graph components"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
