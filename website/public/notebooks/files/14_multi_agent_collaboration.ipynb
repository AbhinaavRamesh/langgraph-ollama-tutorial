{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 14: Multi-Agent Collaboration\n",
    "\n",
    "In this tutorial, you'll build a team of specialized agents that collaborate on complex tasks using the **supervisor pattern**.\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to create a supervisor agent that coordinates multiple specialists\n",
    "- Defining specialized agent roles (researcher, coder, reviewer)\n",
    "- State management for multi-agent systems with output accumulation\n",
    "- Routing decisions between agents using structured output\n",
    "- Synthesizing outputs from multiple agents into a final result\n",
    "\n",
    "By the end, you'll have a working multi-agent system where a supervisor coordinates researcher, coder, and reviewer agents to complete complex tasks.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Tutorials 01-07 (Core Patterns)\n",
    "- Understanding of StateGraph, nodes, and conditional edges\n",
    "- Ollama running with a capable model (llama3.1:8b or larger recommended for tool calling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Multi-Agent Collaboration?\n",
    "\n",
    "Single agents work well for simple tasks, but complex tasks often benefit from:\n",
    "\n",
    "1. **Specialization**: Different agents excel at different tasks (research vs coding vs review)\n",
    "2. **Quality Control**: Review agents can catch errors before final output\n",
    "3. **Modularity**: Each agent can be improved independently\n",
    "4. **Scalability**: Add new specialist agents as needed\n",
    "\n",
    "The **supervisor pattern** uses a central coordinator that:\n",
    "- Understands the overall task\n",
    "- Decides which specialist should work next\n",
    "- Tracks progress and knows when to stop\n",
    "\n",
    "```\n",
    "                     ┌─────────────────┐\n",
    "                     │   Supervisor    │\n",
    "                     │     Agent       │\n",
    "                     └────────┬────────┘\n",
    "                              │\n",
    "          ┌───────────────────┼───────────────────┐\n",
    "          │                   │                   │\n",
    "          ▼                   ▼                   ▼\n",
    "   ┌─────────────┐     ┌─────────────┐     ┌─────────────┐\n",
    "   │  Researcher │     │   Coder     │     │  Reviewer   │\n",
    "   └─────────────┘     └─────────────┘     └─────────────┘\n",
    "          │                   │                   │\n",
    "          └───────────────────┴───────────────────┘\n",
    "                              │\n",
    "                              ▼\n",
    "                     ┌─────────────────┐\n",
    "                     │   Synthesize    │\n",
    "                     └─────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Verify Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify our setup\n",
    "from langgraph_ollama_local import LocalAgentConfig\n",
    "\n",
    "config = LocalAgentConfig()\n",
    "print(f\"Ollama URL: {config.ollama.base_url}\")\n",
    "print(f\"Model: {config.ollama.model}\")\n",
    "print(\"Setup verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the Multi-Agent State\n",
    "\n",
    "Our state needs to track:\n",
    "- The task being worked on\n",
    "- Which agent should run next (supervisor's decision)\n",
    "- Accumulated outputs from all agents\n",
    "- Iteration count to prevent infinite loops\n",
    "- The final synthesized result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "import operator\n",
    "\n",
    "\n",
    "class MultiAgentState(TypedDict):\n",
    "    \"\"\"State schema for multi-agent collaboration.\"\"\"\n",
    "    \n",
    "    # Conversation history - accumulates messages\n",
    "    messages: Annotated[list, add_messages]\n",
    "    \n",
    "    # The task to complete\n",
    "    task: str\n",
    "    \n",
    "    # Supervisor's routing decision\n",
    "    next_agent: str\n",
    "    \n",
    "    # Accumulated agent outputs - uses operator.add to append\n",
    "    agent_outputs: Annotated[list[dict], operator.add]\n",
    "    \n",
    "    # Iteration tracking\n",
    "    iteration: int\n",
    "    max_iterations: int\n",
    "    \n",
    "    # Final result\n",
    "    final_result: str\n",
    "\n",
    "\n",
    "print(\"State defined!\")\n",
    "print(\"\\nKey fields:\")\n",
    "print(\"- agent_outputs: Uses operator.add to accumulate outputs from each agent\")\n",
    "print(\"- next_agent: Set by supervisor to route to the right specialist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create the Supervisor with Structured Output\n",
    "\n",
    "The supervisor uses **structured output** to make routing decisions. This ensures reliable parsing of which agent should work next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "class SupervisorDecision(BaseModel):\n",
    "    \"\"\"Structured output for supervisor routing.\"\"\"\n",
    "    \n",
    "    next_agent: Literal[\"researcher\", \"coder\", \"reviewer\", \"FINISH\"] = Field(\n",
    "        description=\"The next agent to work, or FINISH if complete\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"Brief explanation for this decision\"\n",
    "    )\n",
    "\n",
    "\n",
    "SUPERVISOR_PROMPT = \"\"\"You are a supervisor managing a team of specialized agents.\n",
    "\n",
    "Your team:\n",
    "- **researcher**: Analyzes requirements, gathers information, researches solutions\n",
    "- **coder**: Writes code, implements solutions\n",
    "- **reviewer**: Reviews work quality, checks for issues\n",
    "\n",
    "Based on the task and progress, decide which agent should work next.\n",
    "When the task is complete, respond with FINISH.\n",
    "\n",
    "Guidelines:\n",
    "- Start with researcher for tasks needing analysis\n",
    "- Use coder when requirements are clear\n",
    "- Use reviewer after code is written\n",
    "- Be efficient - most tasks need 2-4 agent turns\"\"\"\n",
    "\n",
    "\n",
    "def create_supervisor_node(llm):\n",
    "    \"\"\"Create a supervisor that routes work to agents.\"\"\"\n",
    "    \n",
    "    # Use structured output for reliable parsing\n",
    "    structured_llm = llm.with_structured_output(SupervisorDecision)\n",
    "    \n",
    "    def supervisor(state: MultiAgentState) -> dict:\n",
    "        # Summarize progress\n",
    "        outputs = state.get(\"agent_outputs\", [])\n",
    "        if outputs:\n",
    "            progress = \"\\n\".join([\n",
    "                f\"**{o['agent']}**: {o['output'][:300]}...\"\n",
    "                for o in outputs\n",
    "            ])\n",
    "        else:\n",
    "            progress = \"No work completed yet.\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=SUPERVISOR_PROMPT),\n",
    "            HumanMessage(content=f\"\"\"Task: {state['task']}\n",
    "\n",
    "Progress:\n",
    "{progress}\n",
    "\n",
    "Iteration {state['iteration'] + 1}/{state['max_iterations']}\n",
    "\n",
    "Which agent should work next?\"\"\")\n",
    "        ]\n",
    "        \n",
    "        decision = structured_llm.invoke(messages)\n",
    "        \n",
    "        return {\n",
    "            \"next_agent\": decision.next_agent,\n",
    "            \"iteration\": state[\"iteration\"] + 1,\n",
    "            \"messages\": [AIMessage(\n",
    "                content=f\"[Supervisor] Next: {decision.next_agent}. {decision.reasoning}\"\n",
    "            )]\n",
    "        }\n",
    "    \n",
    "    return supervisor\n",
    "\n",
    "\n",
    "print(\"Supervisor node creator defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Specialized Agent Nodes\n",
    "\n",
    "Each specialist agent has a focused role and system prompt. They all follow the same pattern but with different expertise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_PROMPTS = {\n",
    "    \"researcher\": \"\"\"You are a research agent. Your job is to:\n",
    "- Analyze task requirements\n",
    "- Research best practices and solutions\n",
    "- Identify potential challenges\n",
    "\n",
    "Provide clear, actionable analysis.\"\"\",\n",
    "\n",
    "    \"coder\": \"\"\"You are a coding agent. Your job is to:\n",
    "- Write clean, documented code\n",
    "- Implement solutions based on requirements\n",
    "- Follow best practices\n",
    "\n",
    "Write production-quality code with examples.\"\"\",\n",
    "\n",
    "    \"reviewer\": \"\"\"You are a review agent. Your job is to:\n",
    "- Review code for correctness and style\n",
    "- Check if requirements are met\n",
    "- Provide constructive feedback\n",
    "\n",
    "Be specific about strengths and improvements needed.\"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "def create_agent_node(llm, agent_name: str):\n",
    "    \"\"\"Create a specialized agent node.\"\"\"\n",
    "    \n",
    "    system_prompt = AGENT_PROMPTS.get(agent_name, \"You are a helpful assistant.\")\n",
    "    \n",
    "    def agent(state: MultiAgentState) -> dict:\n",
    "        # Build context from previous work\n",
    "        outputs = state.get(\"agent_outputs\", [])\n",
    "        if outputs:\n",
    "            context = \"\\n\\n\".join([\n",
    "                f\"**{o['agent']}**: {o['output']}\"\n",
    "                for o in outputs\n",
    "            ])\n",
    "        else:\n",
    "            context = \"No previous work.\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=f\"\"\"Task: {state['task']}\n",
    "\n",
    "Previous work:\n",
    "{context}\n",
    "\n",
    "Provide your contribution.\"\"\")\n",
    "        ]\n",
    "        \n",
    "        response = llm.invoke(messages)\n",
    "        \n",
    "        return {\n",
    "            \"agent_outputs\": [{\n",
    "                \"agent\": agent_name,\n",
    "                \"output\": response.content\n",
    "            }],\n",
    "            \"messages\": [AIMessage(\n",
    "                content=f\"[{agent_name.title()}] {response.content}\"\n",
    "            )]\n",
    "        }\n",
    "    \n",
    "    return agent\n",
    "\n",
    "\n",
    "print(\"Agent node creator defined!\")\n",
    "print(\"\\nAvailable agent types:\", list(AGENT_PROMPTS.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create the Synthesize Node\n",
    "\n",
    "When the supervisor decides the task is complete, this node combines all agent outputs into a final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_node(state: MultiAgentState) -> dict:\n",
    "    \"\"\"Combine all agent outputs into final result.\"\"\"\n",
    "    \n",
    "    outputs = state.get(\"agent_outputs\", [])\n",
    "    \n",
    "    if not outputs:\n",
    "        return {\"final_result\": \"No work was completed.\"}\n",
    "    \n",
    "    # Group by agent\n",
    "    by_agent = {}\n",
    "    for output in outputs:\n",
    "        agent = output[\"agent\"]\n",
    "        if agent not in by_agent:\n",
    "            by_agent[agent] = []\n",
    "        by_agent[agent].append(output[\"output\"])\n",
    "    \n",
    "    # Build formatted result\n",
    "    parts = []\n",
    "    for agent_name in [\"researcher\", \"coder\", \"reviewer\"]:\n",
    "        if agent_name in by_agent:\n",
    "            parts.append(f\"## {agent_name.title()} Output\")\n",
    "            for output in by_agent[agent_name]:\n",
    "                parts.append(output)\n",
    "            parts.append(\"\")\n",
    "    \n",
    "    return {\n",
    "        \"final_result\": \"\\n\\n\".join(parts).strip(),\n",
    "        \"messages\": [AIMessage(content=\"[System] Task completed.\")]\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Synthesize node defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Define the Routing Function\n",
    "\n",
    "This function reads the supervisor's decision and routes to the appropriate agent or to synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_supervisor(state: MultiAgentState) -> str:\n",
    "    \"\"\"Route based on supervisor's decision.\"\"\"\n",
    "    \n",
    "    next_agent = state.get(\"next_agent\", \"\")\n",
    "    iteration = state.get(\"iteration\", 0)\n",
    "    max_iterations = state.get(\"max_iterations\", 10)\n",
    "    \n",
    "    # Force completion at max iterations\n",
    "    if iteration >= max_iterations:\n",
    "        print(f\"  [Router] Max iterations reached, going to synthesize\")\n",
    "        return \"synthesize\"\n",
    "    \n",
    "    # Route based on decision\n",
    "    if next_agent == \"FINISH\":\n",
    "        print(f\"  [Router] Task complete, going to synthesize\")\n",
    "        return \"synthesize\"\n",
    "    \n",
    "    if next_agent.lower() in [\"researcher\", \"coder\", \"reviewer\"]:\n",
    "        print(f\"  [Router] Routing to {next_agent.lower()}\")\n",
    "        return next_agent.lower()\n",
    "    \n",
    "    # Default to synthesize\n",
    "    print(f\"  [Router] Unknown decision '{next_agent}', going to synthesize\")\n",
    "    return \"synthesize\"\n",
    "\n",
    "\n",
    "print(\"Routing function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Build the Complete Graph\n",
    "\n",
    "Now we assemble all the pieces into a working multi-agent graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Create LLM\n",
    "llm = ChatOllama(\n",
    "    model=config.ollama.model,\n",
    "    base_url=config.ollama.base_url,\n",
    "    temperature=0,  # Deterministic for routing\n",
    ")\n",
    "\n",
    "# Build the graph\n",
    "workflow = StateGraph(MultiAgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"supervisor\", create_supervisor_node(llm))\n",
    "workflow.add_node(\"researcher\", create_agent_node(llm, \"researcher\"))\n",
    "workflow.add_node(\"coder\", create_agent_node(llm, \"coder\"))\n",
    "workflow.add_node(\"reviewer\", create_agent_node(llm, \"reviewer\"))\n",
    "workflow.add_node(\"synthesize\", synthesize_node)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "\n",
    "# Supervisor routes to agents or synthesize\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    route_supervisor,\n",
    "    {\n",
    "        \"researcher\": \"researcher\",\n",
    "        \"coder\": \"coder\",\n",
    "        \"reviewer\": \"reviewer\",\n",
    "        \"synthesize\": \"synthesize\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# All agents return to supervisor\n",
    "workflow.add_edge(\"researcher\", \"supervisor\")\n",
    "workflow.add_edge(\"coder\", \"supervisor\")\n",
    "workflow.add_edge(\"reviewer\", \"supervisor\")\n",
    "\n",
    "# Synthesize ends the graph\n",
    "workflow.add_edge(\"synthesize\", END)\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()\n",
    "\n",
    "print(\"Multi-agent graph compiled!\")\n",
    "print(\"\\nGraph structure:\")\n",
    "print(\"  START -> supervisor\")\n",
    "print(\"  supervisor -> [researcher | coder | reviewer | synthesize]\")\n",
    "print(\"  researcher -> supervisor\")\n",
    "print(\"  coder -> supervisor\")\n",
    "print(\"  reviewer -> supervisor\")\n",
    "print(\"  synthesize -> END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Run the Multi-Agent System\n",
    "\n",
    "Let's test our multi-agent system with a real task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task(task: str, max_iterations: int = 6):\n",
    "    \"\"\"Run a task through the multi-agent system.\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"Task: {task}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=f\"Task: {task}\")],\n",
    "        \"task\": task,\n",
    "        \"next_agent\": \"\",\n",
    "        \"agent_outputs\": [],\n",
    "        \"iteration\": 0,\n",
    "        \"max_iterations\": max_iterations,\n",
    "        \"final_result\": \"\",\n",
    "    }\n",
    "    \n",
    "    result = graph.invoke(initial_state)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL RESULT\")\n",
    "    print(\"=\"*60)\n",
    "    print(result[\"final_result\"])\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Completed in {result['iteration']} iterations\")\n",
    "    print(f\"Agent outputs: {len(result['agent_outputs'])}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Test with a coding task\n",
    "result = run_task(\n",
    "    \"Create a Python function to check if a string is a valid palindrome (ignoring spaces and case)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Try Different Tasks\n",
    "\n",
    "The multi-agent system can handle various types of tasks. Let's try a few more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research-heavy task\n",
    "result2 = run_task(\n",
    "    \"Explain the best practices for error handling in Python async code\",\n",
    "    max_iterations=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation task\n",
    "result3 = run_task(\n",
    "    \"Create a simple LRU cache class in Python with get and put methods\",\n",
    "    max_iterations=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Using the Built-in Module\n",
    "\n",
    "The `langgraph_ollama_local.agents` module provides a ready-to-use implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_ollama_local.agents import (\n",
    "    create_multi_agent_graph,\n",
    "    run_multi_agent_task,\n",
    ")\n",
    "\n",
    "# Create the graph using the module\n",
    "module_graph = create_multi_agent_graph(llm)\n",
    "\n",
    "# Run a task\n",
    "result = run_multi_agent_task(\n",
    "    module_graph,\n",
    "    \"Write a Python decorator that logs function execution time\",\n",
    "    max_iterations=5\n",
    ")\n",
    "\n",
    "print(\"Final Result:\")\n",
    "print(result[\"final_result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Code\n",
    "\n",
    "Here's the complete implementation in one cell for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Complete Multi-Agent Collaboration Implementation ===\n",
    "\n",
    "from typing import Annotated, Literal\n",
    "from typing_extensions import TypedDict\n",
    "import operator\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langgraph_ollama_local import LocalAgentConfig\n",
    "\n",
    "\n",
    "# === State ===\n",
    "class MultiAgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    task: str\n",
    "    next_agent: str\n",
    "    agent_outputs: Annotated[list[dict], operator.add]\n",
    "    iteration: int\n",
    "    max_iterations: int\n",
    "    final_result: str\n",
    "\n",
    "\n",
    "# === Structured Output ===\n",
    "class SupervisorDecision(BaseModel):\n",
    "    next_agent: Literal[\"researcher\", \"coder\", \"reviewer\", \"FINISH\"] = Field(\n",
    "        description=\"Next agent or FINISH\"\n",
    "    )\n",
    "    reasoning: str = Field(description=\"Brief explanation\")\n",
    "\n",
    "\n",
    "# === Prompts ===\n",
    "SUPERVISOR_PROMPT = \"\"\"You manage researcher, coder, and reviewer agents.\n",
    "Decide who works next based on task and progress. Say FINISH when done.\"\"\"\n",
    "\n",
    "AGENT_PROMPTS = {\n",
    "    \"researcher\": \"Analyze requirements and research solutions.\",\n",
    "    \"coder\": \"Write clean, documented code.\",\n",
    "    \"reviewer\": \"Review quality and provide feedback.\",\n",
    "}\n",
    "\n",
    "\n",
    "# === Node Creators ===\n",
    "def create_supervisor(llm):\n",
    "    structured_llm = llm.with_structured_output(SupervisorDecision)\n",
    "    \n",
    "    def supervisor(state):\n",
    "        outputs = state.get(\"agent_outputs\", [])\n",
    "        progress = \"\\n\".join([f\"{o['agent']}: {o['output'][:200]}\" for o in outputs]) or \"None\"\n",
    "        \n",
    "        decision = structured_llm.invoke([\n",
    "            SystemMessage(content=SUPERVISOR_PROMPT),\n",
    "            HumanMessage(content=f\"Task: {state['task']}\\nProgress: {progress}\")\n",
    "        ])\n",
    "        \n",
    "        return {\"next_agent\": decision.next_agent, \"iteration\": state[\"iteration\"] + 1}\n",
    "    \n",
    "    return supervisor\n",
    "\n",
    "\n",
    "def create_agent(llm, name):\n",
    "    def agent(state):\n",
    "        response = llm.invoke([\n",
    "            SystemMessage(content=AGENT_PROMPTS[name]),\n",
    "            HumanMessage(content=f\"Task: {state['task']}\")\n",
    "        ])\n",
    "        return {\"agent_outputs\": [{\"agent\": name, \"output\": response.content}]}\n",
    "    return agent\n",
    "\n",
    "\n",
    "def synthesize(state):\n",
    "    outputs = state.get(\"agent_outputs\", [])\n",
    "    result = \"\\n\\n\".join([f\"## {o['agent'].title()}\\n{o['output']}\" for o in outputs])\n",
    "    return {\"final_result\": result}\n",
    "\n",
    "\n",
    "# === Routing ===\n",
    "def route(state):\n",
    "    if state[\"iteration\"] >= state[\"max_iterations\"] or state[\"next_agent\"] == \"FINISH\":\n",
    "        return \"synthesize\"\n",
    "    return state[\"next_agent\"].lower() if state[\"next_agent\"].lower() in AGENT_PROMPTS else \"synthesize\"\n",
    "\n",
    "\n",
    "# === Build Graph ===\n",
    "def build_multi_agent_graph():\n",
    "    config = LocalAgentConfig()\n",
    "    llm = ChatOllama(model=config.ollama.model, base_url=config.ollama.base_url, temperature=0)\n",
    "    \n",
    "    g = StateGraph(MultiAgentState)\n",
    "    g.add_node(\"supervisor\", create_supervisor(llm))\n",
    "    g.add_node(\"researcher\", create_agent(llm, \"researcher\"))\n",
    "    g.add_node(\"coder\", create_agent(llm, \"coder\"))\n",
    "    g.add_node(\"reviewer\", create_agent(llm, \"reviewer\"))\n",
    "    g.add_node(\"synthesize\", synthesize)\n",
    "    \n",
    "    g.add_edge(START, \"supervisor\")\n",
    "    g.add_conditional_edges(\"supervisor\", route, \n",
    "        {\"researcher\": \"researcher\", \"coder\": \"coder\", \"reviewer\": \"reviewer\", \"synthesize\": \"synthesize\"})\n",
    "    g.add_edge(\"researcher\", \"supervisor\")\n",
    "    g.add_edge(\"coder\", \"supervisor\")\n",
    "    g.add_edge(\"reviewer\", \"supervisor\")\n",
    "    g.add_edge(\"synthesize\", END)\n",
    "    \n",
    "    return g.compile()\n",
    "\n",
    "\n",
    "# === Use ===\n",
    "if __name__ == \"__main__\":\n",
    "    graph = build_multi_agent_graph()\n",
    "    result = graph.invoke({\n",
    "        \"messages\": [], \"task\": \"Write a function to reverse a linked list\",\n",
    "        \"next_agent\": \"\", \"agent_outputs\": [],\n",
    "        \"iteration\": 0, \"max_iterations\": 5, \"final_result\": \"\"\n",
    "    })\n",
    "    print(result[\"final_result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Supervisor Pattern** | Central agent coordinates multiple specialists |\n",
    "| **Structured Output** | Pydantic models ensure reliable routing decisions |\n",
    "| **State Accumulation** | `operator.add` reducer collects all agent outputs |\n",
    "| **Conditional Routing** | Supervisor decision determines next agent |\n",
    "| **Agent Loop** | Agents return to supervisor until task is complete |\n",
    "| **Max Iterations** | Safety limit prevents infinite loops |\n",
    "| **Synthesis Node** | Combines all outputs into final result |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next\n",
    "\n",
    "- [Tutorial 15: Hierarchical Agent Teams](15_hierarchical_teams.ipynb) - Nested teams with team supervisors\n",
    "- [Tutorial 16: Subgraph Patterns](16_subgraphs.ipynb) - Composable, reusable graph components"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
