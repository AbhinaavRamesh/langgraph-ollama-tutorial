{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Tutorial 11: Adaptive RAG\n",
    "\n",
    "Build a RAG system that **routes queries** to the optimal retrieval strategy based on question type.\n",
    "\n",
    "**What you'll learn:**\n",
    "- **Query Classification**: Categorize questions by type\n",
    "- **Strategy Selection**: Route to appropriate retrieval method\n",
    "- **Multiple Sources**: Vector store, web search, or direct LLM\n",
    "- **Intelligent Routing**: Dynamic path selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Why Adaptive RAG?\n",
    "\n",
    "Not all questions need the same approach:\n",
    "- **Factual about documents**: Use vector store\n",
    "- **Current events**: Use web search\n",
    "- **Simple/general**: Direct LLM response\n",
    "\n",
    "Adaptive RAG routes to the best strategy:\n",
    "\n",
    "```\n",
    "Question → Classify → Route → [VectorStore | WebSearch | Direct] → Generate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from langgraph_ollama_local import LocalAgentConfig\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "config = LocalAgentConfig()\n",
    "llm = ChatOllama(\n",
    "    model=config.ollama.model,\n",
    "    base_url=config.ollama.base_url,\n",
    "    temperature=0,\n",
    ")\n",
    "print(f\"Using model: {config.ollama.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class AdaptiveRAGState(TypedDict):\n",
    "    \"\"\"State for Adaptive RAG.\"\"\"\n",
    "    question: str\n",
    "    query_type: Literal[\"vectorstore\", \"websearch\", \"direct\"]  # Classified type\n",
    "    documents: List[Document]\n",
    "    generation: str\n",
    "\n",
    "print(\"State defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_ollama_local.rag.graders import QueryRouter\n",
    "\n",
    "# Create query router\n",
    "router = QueryRouter(llm)\n",
    "\n",
    "# Test routing\n",
    "test_queries = [\n",
    "    \"What is Self-RAG according to the research papers?\",\n",
    "    \"What happened in the news today?\",\n",
    "    \"What is 2 + 2?\",\n",
    "    \"Explain the CRAG pattern from the documentation\",\n",
    "]\n",
    "\n",
    "print(\"Query routing examples:\")\n",
    "for q in test_queries:\n",
    "    route = router.route(q)\n",
    "    print(f\"  '{q[:40]}...' → {route}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_ollama_local.rag import LocalRetriever\n",
    "\n",
    "retriever = LocalRetriever()\n",
    "\n",
    "# Node functions\n",
    "def classify_query(state: AdaptiveRAGState) -> dict:\n",
    "    \"\"\"Classify the query type.\"\"\"\n",
    "    print(\"--- CLASSIFY QUERY ---\")\n",
    "    query_type = router.route(state[\"question\"])\n",
    "    print(f\"Query type: {query_type}\")\n",
    "    return {\"query_type\": query_type}\n",
    "\n",
    "def retrieve_vectorstore(state: AdaptiveRAGState) -> dict:\n",
    "    \"\"\"Retrieve from vector store.\"\"\"\n",
    "    print(\"--- VECTOR STORE RETRIEVAL ---\")\n",
    "    docs = retriever.retrieve_documents(state[\"question\"], k=4)\n",
    "    print(f\"Retrieved {len(docs)} documents\")\n",
    "    return {\"documents\": docs}\n",
    "\n",
    "def retrieve_websearch(state: AdaptiveRAGState) -> dict:\n",
    "    \"\"\"Retrieve from web search.\"\"\"\n",
    "    print(\"--- WEB SEARCH ---\")\n",
    "    # Simplified web search (use CRAG implementation for full version)\n",
    "    return {\"documents\": [Document(\n",
    "        page_content=f\"Web search results for: {state['question']}\",\n",
    "        metadata={\"type\": \"web\"}\n",
    "    )]}\n",
    "\n",
    "def generate_direct(state: AdaptiveRAGState) -> dict:\n",
    "    \"\"\"Generate direct response without retrieval.\"\"\"\n",
    "    print(\"--- DIRECT GENERATION ---\")\n",
    "    response = llm.invoke(state[\"question\"])\n",
    "    return {\"generation\": response.content, \"documents\": []}\n",
    "\n",
    "def generate_with_context(state: AdaptiveRAGState) -> dict:\n",
    "    \"\"\"Generate response using retrieved context.\"\"\"\n",
    "    print(\"--- GENERATE WITH CONTEXT ---\")\n",
    "    context = \"\\n\\n\".join([d.page_content for d in state[\"documents\"]])\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {state['question']}\\n\\nAnswer:\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"generation\": response.content}\n",
    "\n",
    "print(\"Nodes defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_query(state: AdaptiveRAGState) -> str:\n",
    "    \"\"\"Route based on query classification.\"\"\"\n",
    "    return state[\"query_type\"]\n",
    "\n",
    "print(\"Router defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Build graph\n",
    "graph = StateGraph(AdaptiveRAGState)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"classify\", classify_query)\n",
    "graph.add_node(\"vectorstore\", retrieve_vectorstore)\n",
    "graph.add_node(\"websearch\", retrieve_websearch)\n",
    "graph.add_node(\"direct\", generate_direct)\n",
    "graph.add_node(\"generate\", generate_with_context)\n",
    "\n",
    "# Add edges\n",
    "graph.add_edge(START, \"classify\")\n",
    "\n",
    "# Route based on classification\n",
    "graph.add_conditional_edges(\n",
    "    \"classify\",\n",
    "    route_query,\n",
    "    {\n",
    "        \"vectorstore\": \"vectorstore\",\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"direct\": \"direct\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Retrieval nodes go to generate\n",
    "graph.add_edge(\"vectorstore\", \"generate\")\n",
    "graph.add_edge(\"websearch\", \"generate\")\n",
    "\n",
    "# All paths end\n",
    "graph.add_edge(\"direct\", END)\n",
    "graph.add_edge(\"generate\", END)\n",
    "\n",
    "adaptive_rag = graph.compile()\n",
    "print(\"Adaptive RAG compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "from IPython.display import Image, display\n",
    "try:\n",
    "    display(Image(adaptive_rag.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    print(adaptive_rag.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Document question (vectorstore)\n",
    "result1 = adaptive_rag.invoke({\"question\": \"What is Self-RAG according to the papers?\"})\n",
    "print(f\"Route: {result1['query_type']}\")\n",
    "print(f\"Answer: {result1['generation'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Simple question (direct)\n",
    "result2 = adaptive_rag.invoke({\"question\": \"What is 2 + 2?\"})\n",
    "print(f\"Route: {result2['query_type']}\")\n",
    "print(f\"Answer: {result2['generation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "| Component | Purpose |\n",
    "|-----------|--------|\n",
    "| **QueryRouter** | Classifies question type |\n",
    "| **Conditional Edges** | Routes to appropriate strategy |\n",
    "| **Multiple Paths** | Different retrieval for different needs |\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "In [Tutorial 12: Agentic RAG](12_agentic_rag.ipynb), you'll learn:\n",
    "- Multi-step retrieval with an agent loop\n",
    "- Query decomposition\n",
    "- Iterative refinement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
