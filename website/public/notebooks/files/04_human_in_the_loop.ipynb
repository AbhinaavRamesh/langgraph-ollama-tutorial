{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Tutorial 04: Human-in-the-Loop\n",
    "\n",
    "In this tutorial, you'll learn how to pause agent execution for human review and approval before taking sensitive actions.\n",
    "\n",
    "**What you'll learn:**\n",
    "- **Interrupts**: Pausing graph execution\n",
    "- **interrupt_before**: Static breakpoints at compile time\n",
    "- **interrupt()**: Dynamic breakpoints at runtime\n",
    "- **Command**: Resuming execution with human input\n",
    "- **Approval workflows**: Review before action\n",
    "\n",
    "By the end, you'll have an agent that asks for approval before executing sensitive tool calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Why Human-in-the-Loop?\n",
    "\n",
    "Agents are powerful but not infallible. Before an agent:\n",
    "- Sends an email\n",
    "- Makes a purchase\n",
    "- Deletes data\n",
    "- Calls an external API\n",
    "\n",
    "You might want a human to review and approve the action.\n",
    "\n",
    "### Common Patterns\n",
    "\n",
    "1. **Approve/Reject**: Review tool calls before execution\n",
    "2. **Edit State**: Modify agent's proposed action\n",
    "3. **Provide Input**: Ask human for additional information\n",
    "4. **Review Output**: Validate before returning to user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Graph Visualization\n",
    "\n",
    "![Human-in-the-Loop Graph](../docs/images/04-human-in-loop-graph.png)\n",
    "\n",
    "The graph pauses before the `tools` node, allowing human review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from langgraph_ollama_local import LocalAgentConfig\n",
    "\n",
    "config = LocalAgentConfig()\n",
    "print(f\"Ollama: {config.ollama.base_url}\")\n",
    "print(f\"Model: {config.ollama.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Step 1: Build a Tool-Calling Agent\n",
    "\n",
    "First, let's create a ReAct agent like Tutorial 02:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Define a \"sensitive\" tool\n",
    "@tool\n",
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send an email to a recipient.\n",
    "    \n",
    "    Args:\n",
    "        to: Email address of recipient\n",
    "        subject: Email subject line\n",
    "        body: Email body content\n",
    "    \"\"\"\n",
    "    # In production, this would actually send an email!\n",
    "    return f\"Email sent to {to} with subject: {subject}\"\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get weather for a location.\"\"\"\n",
    "    return f\"Weather in {location}: Sunny, 72°F\"\n",
    "\n",
    "tools = [send_email, get_weather]\n",
    "tools_by_name = {t.name: t for t in tools}\n",
    "\n",
    "# Create LLM with tools\n",
    "llm = ChatOllama(\n",
    "    model=config.ollama.model,\n",
    "    base_url=config.ollama.base_url,\n",
    "    temperature=0,\n",
    ").bind_tools(tools)\n",
    "\n",
    "print(f\"Tools: {[t.name for t in tools]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State and nodes\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def agent_node(state: State) -> dict:\n",
    "    \"\"\"Call LLM to decide on action.\"\"\"\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def tool_node(state: State) -> dict:\n",
    "    \"\"\"Execute tool calls.\"\"\"\n",
    "    outputs = []\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    for tc in last_message.tool_calls:\n",
    "        print(f\"  Executing: {tc['name']}({tc['args']})\")\n",
    "        result = tools_by_name[tc[\"name\"]].invoke(tc[\"args\"])\n",
    "        outputs.append(ToolMessage(\n",
    "            content=json.dumps(result),\n",
    "            name=tc[\"name\"],\n",
    "            tool_call_id=tc[\"id\"],\n",
    "        ))\n",
    "    \n",
    "    return {\"messages\": outputs}\n",
    "\n",
    "def should_continue(state: State) -> str:\n",
    "    \"\"\"Route based on tool calls.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 2: Add interrupt_before\n",
    "\n",
    "The simplest way to add human review is `interrupt_before`. This pauses the graph **before** a node runs.\n",
    "\n",
    "```python\n",
    "graph = workflow.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=[\"tools\"]  # Pause before tools node\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph with interrupt_before\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\", should_continue, {\"tools\": \"tools\", \"end\": END}\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile with interrupt_before\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=[\"tools\"]  # Pause before executing tools\n",
    ")\n",
    "\n",
    "print(\"Graph compiled with interrupt_before=['tools']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 3: Trigger an Interrupt\n",
    "\n",
    "When the agent decides to call a tool, execution will pause:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a conversation that will trigger a tool call\n",
    "thread_config = {\"configurable\": {\"thread_id\": \"email-approval-1\"}}\n",
    "\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [(\"user\", \"Send an email to alice@example.com saying 'Hello from the agent!'\")]},\n",
    "    config=thread_config\n",
    ")\n",
    "\n",
    "print(\"Execution paused!\")\n",
    "print(f\"Number of messages: {len(result['messages'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what action is pending\n",
    "state = graph.get_state(thread_config)\n",
    "\n",
    "print(f\"Next node to run: {state.next}\")\n",
    "print()\n",
    "\n",
    "# Get the pending tool calls\n",
    "last_message = state.values[\"messages\"][-1]\n",
    "if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "    print(\"Pending tool calls:\")\n",
    "    for tc in last_message.tool_calls:\n",
    "        print(f\"  Tool: {tc['name']}\")\n",
    "        print(f\"  Args: {tc['args']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Step 4: Review and Resume\n",
    "\n",
    "At this point, a human can:\n",
    "1. **Approve**: Resume execution with `None` (continue as-is)\n",
    "2. **Reject**: Don't resume, end the conversation\n",
    "3. **Modify**: Update state before resuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROVE: Resume execution (pass None to continue)\n",
    "print(\"Human approves the email...\")\n",
    "\n",
    "result = graph.invoke(None, config=thread_config)\n",
    "\n",
    "print(f\"\\nFinal response: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Step 5: Rejection Example\n",
    "\n",
    "Let's see what happens when we don't approve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new conversation\n",
    "thread_config2 = {\"configurable\": {\"thread_id\": \"email-approval-2\"}}\n",
    "\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [(\"user\", \"Send an email to boss@company.com with subject 'I quit!'\")]},\n",
    "    config=thread_config2\n",
    ")\n",
    "\n",
    "# Check pending action\n",
    "state = graph.get_state(thread_config2)\n",
    "last_msg = state.values[\"messages\"][-1]\n",
    "\n",
    "print(\"Pending action:\")\n",
    "for tc in last_msg.tool_calls:\n",
    "    print(f\"  {tc['name']}({tc['args']})\")\n",
    "print()\n",
    "print(\"Human REJECTS this action!\")\n",
    "print(\"(Simply don't call invoke again - the thread is paused)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Step 6: Safe Actions (No Interrupt)\n",
    "\n",
    "Not all tools need approval. Let's see what happens with a safe tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather is safe - still goes through interrupt\n",
    "thread_config3 = {\"configurable\": {\"thread_id\": \"weather-check\"}}\n",
    "\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [(\"user\", \"What's the weather in San Francisco?\")]},\n",
    "    config=thread_config3\n",
    ")\n",
    "\n",
    "# Check if interrupted\n",
    "state = graph.get_state(thread_config3)\n",
    "print(f\"Next node: {state.next}\")\n",
    "\n",
    "if state.next:\n",
    "    print(\"Graph is paused (even for safe tools with current config)\")\n",
    "    # Auto-approve weather checks\n",
    "    result = graph.invoke(None, config=thread_config3)\n",
    "    print(f\"Result: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Step 7: Selective Interrupts\n",
    "\n",
    "For more control, you can check the tool type and only interrupt for sensitive ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which tools are sensitive\n",
    "SENSITIVE_TOOLS = {\"send_email\"}\n",
    "\n",
    "def should_continue_selective(state: State) -> str:\n",
    "    \"\"\"Route based on tool type - only interrupt for sensitive tools.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        # Check if any tool is sensitive\n",
    "        for tc in last_message.tool_calls:\n",
    "            if tc[\"name\"] in SENSITIVE_TOOLS:\n",
    "                return \"sensitive_tools\"  # Route to node with interrupt\n",
    "        return \"safe_tools\"  # Route to node without interrupt\n",
    "    return \"end\"\n",
    "\n",
    "print(f\"Sensitive tools: {SENSITIVE_TOOLS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build selective interrupt graph\n",
    "def sensitive_tool_node(state: State) -> dict:\n",
    "    \"\"\"Execute sensitive tools (with interrupt before).\"\"\"\n",
    "    return tool_node(state)\n",
    "\n",
    "def safe_tool_node(state: State) -> dict:\n",
    "    \"\"\"Execute safe tools (no interrupt).\"\"\"\n",
    "    return tool_node(state)\n",
    "\n",
    "workflow2 = StateGraph(State)\n",
    "workflow2.add_node(\"agent\", agent_node)\n",
    "workflow2.add_node(\"sensitive_tools\", sensitive_tool_node)\n",
    "workflow2.add_node(\"safe_tools\", safe_tool_node)\n",
    "\n",
    "workflow2.add_edge(START, \"agent\")\n",
    "workflow2.add_conditional_edges(\n",
    "    \"agent\", \n",
    "    should_continue_selective, \n",
    "    {\"sensitive_tools\": \"sensitive_tools\", \"safe_tools\": \"safe_tools\", \"end\": END}\n",
    ")\n",
    "workflow2.add_edge(\"sensitive_tools\", \"agent\")\n",
    "workflow2.add_edge(\"safe_tools\", \"agent\")\n",
    "\n",
    "memory2 = MemorySaver()\n",
    "graph2 = workflow2.compile(\n",
    "    checkpointer=memory2,\n",
    "    interrupt_before=[\"sensitive_tools\"]  # Only interrupt sensitive\n",
    ")\n",
    "\n",
    "print(\"Selective interrupt graph compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Weather (safe) - should NOT interrupt\n",
    "thread_safe = {\"configurable\": {\"thread_id\": \"safe-test\"}}\n",
    "\n",
    "result = graph2.invoke(\n",
    "    {\"messages\": [(\"user\", \"What's the weather in London?\")]},\n",
    "    config=thread_safe\n",
    ")\n",
    "\n",
    "state = graph2.get_state(thread_safe)\n",
    "if not state.next:\n",
    "    print(\"Safe tool executed without interrupt!\")\n",
    "    print(f\"Result: {result['messages'][-1].content}\")\n",
    "else:\n",
    "    print(f\"Unexpectedly interrupted at: {state.next}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Email (sensitive) - SHOULD interrupt\n",
    "thread_sensitive = {\"configurable\": {\"thread_id\": \"sensitive-test\"}}\n",
    "\n",
    "result = graph2.invoke(\n",
    "    {\"messages\": [(\"user\", \"Email john@example.com with 'Meeting tomorrow'\")]},\n",
    "    config=thread_sensitive\n",
    ")\n",
    "\n",
    "state = graph2.get_state(thread_sensitive)\n",
    "if state.next:\n",
    "    print(f\"Interrupted before: {state.next}\")\n",
    "    print(\"Human review required for sensitive action!\")\n",
    "else:\n",
    "    print(\"Unexpected: did not interrupt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Complete Code: Approval Workflow\n",
    "\n",
    "Here's a complete example with an approval helper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_approval(user_input: str, thread_id: str, auto_approve: bool = False):\n",
    "    \"\"\"Run agent with human approval workflow.\"\"\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    # Initial run\n",
    "    result = graph.invoke({\"messages\": [(\"user\", user_input)]}, config=config)\n",
    "    \n",
    "    while True:\n",
    "        state = graph.get_state(config)\n",
    "        \n",
    "        # Check if we're done\n",
    "        if not state.next:\n",
    "            break\n",
    "        \n",
    "        # Show pending actions\n",
    "        last_msg = state.values[\"messages\"][-1]\n",
    "        if hasattr(last_msg, \"tool_calls\"):\n",
    "            print(\"\\n=== APPROVAL REQUIRED ===\")\n",
    "            for tc in last_msg.tool_calls:\n",
    "                print(f\"Action: {tc['name']}\")\n",
    "                print(f\"Args: {tc['args']}\")\n",
    "            print(\"=========================\")\n",
    "        \n",
    "        if auto_approve:\n",
    "            print(\"Auto-approving...\")\n",
    "            result = graph.invoke(None, config=config)\n",
    "        else:\n",
    "            # In production, you'd get input from a UI\n",
    "            approval = input(\"Approve? (y/n): \")\n",
    "            if approval.lower() == 'y':\n",
    "                result = graph.invoke(None, config=config)\n",
    "            else:\n",
    "                print(\"Action rejected!\")\n",
    "                break\n",
    "    \n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "# Test with auto-approve\n",
    "response = run_with_approval(\n",
    "    \"Send an email to test@example.com saying 'Test message'\",\n",
    "    \"approval-demo\",\n",
    "    auto_approve=True\n",
    ")\n",
    "print(f\"\\nFinal: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Key Concepts Recap\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **interrupt_before** | Pause before a node runs |\n",
    "| **interrupt_after** | Pause after a node runs |\n",
    "| **state.next** | Shows which node will run next (None if done) |\n",
    "| **invoke(None, config)** | Resume a paused graph |\n",
    "| **get_state(config)** | Inspect current state |\n",
    "\n",
    "## Common Patterns\n",
    "\n",
    "1. **Approve all tools**: `interrupt_before=[\"tools\"]`\n",
    "2. **Selective approval**: Route to different nodes based on tool type\n",
    "3. **Edit before execute**: Modify state before resuming\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "In [Tutorial 05: Reflection](05_reflection.ipynb), you'll learn:\n",
    "- Self-critique loops for quality improvement\n",
    "- Generate → Reflect → Revise patterns\n",
    "- Iterative refinement of outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
