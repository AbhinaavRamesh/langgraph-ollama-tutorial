{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Tutorial 21: Plan-and-Execute Pattern\n",
    "\n",
    "In this tutorial, you'll build a **plan-and-execute pattern** for complex multi-step tasks with adaptive replanning.\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to break complex tasks into step-by-step plans\n",
    "- Executing plans sequentially with context from previous steps\n",
    "- Implementing replanning to adapt based on execution results\n",
    "- When to use plan-execute vs pure ReAct agents\n",
    "- Combining planning with tool-enabled execution\n",
    "\n",
    "By the end, you'll have a working plan-and-execute system that plans, executes, and adapts.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Tutorial 02 (Tool Calling and ReAct)\n",
    "- Understanding of multi-step reasoning\n",
    "- Ollama running with a capable model (llama3.1:8b or larger recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Why Plan-and-Execute?\n",
    "\n",
    "ReAct agents (Tutorial 02) make step-by-step decisions without a global plan. This works well for simple tasks but has limitations:\n",
    "\n",
    "1. **No Lookahead**: Can't optimize the overall approach\n",
    "2. **Token Inefficient**: Every step requires full context\n",
    "3. **Hard to Debug**: Can't see the intended strategy upfront\n",
    "4. **Resource Waste**: Uses expensive model for every micro-decision\n",
    "\n",
    "**Plan-and-Execute advantages:**\n",
    "- Explicit plan visible before execution\n",
    "- Can use different models for planning vs execution\n",
    "- Better for multi-step tasks requiring coordination\n",
    "- Easier to debug and validate\n",
    "- Supports replanning when needed\n",
    "\n",
    "```\n",
    "┌─────────┐     ┌──────────┐     ┌───────────┐\n",
    "│ Planner │────►│ Executor │────►│ Replanner │\n",
    "└─────────┘     └──────────┘     └─────┬─────┘\n",
    "                      ↑                 │\n",
    "                      │    New Plan     │ Done?\n",
    "                      └─────────────────┤\n",
    "                                        │\n",
    "                                        ▼\n",
    "                                   ┌────────┐\n",
    "                                   │  END   │\n",
    "                                   └────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Verify Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify our setup\n",
    "from langgraph_ollama_local import LocalAgentConfig\n",
    "\n",
    "config = LocalAgentConfig()\n",
    "print(f\"Ollama URL: {config.ollama.base_url}\")\n",
    "print(f\"Model: {config.ollama.model}\")\n",
    "print(\"Setup verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Step 2: Define the Plan-Execute State\n",
    "\n",
    "Our state tracks:\n",
    "- The original task\n",
    "- The current plan (list of steps)\n",
    "- Past executed steps with results\n",
    "- Current step index\n",
    "- Final response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "import operator\n",
    "\n",
    "\n",
    "class PlanExecuteState(TypedDict):\n",
    "    \"\"\"State schema for plan-and-execute pattern.\"\"\"\n",
    "    \n",
    "    # Original task to accomplish\n",
    "    task: str\n",
    "    \n",
    "    # Current plan (list of step descriptions)\n",
    "    plan: list[str]\n",
    "    \n",
    "    # History of (step, result) pairs - uses operator.add to accumulate\n",
    "    past_steps: Annotated[list[tuple[str, str]], operator.add]\n",
    "    \n",
    "    # Index of current step to execute\n",
    "    current_step: int\n",
    "    \n",
    "    # Final response when complete\n",
    "    response: str\n",
    "\n",
    "\n",
    "print(\"State defined!\")\n",
    "print(\"\\nKey fields:\")\n",
    "print(\"- plan: List of step descriptions\")\n",
    "print(\"- past_steps: Accumulated (step, result) using operator.add\")\n",
    "print(\"- current_step: Tracks progress through plan\")\n",
    "print(\"- response: Final answer when task is complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Step 3: Create the Planner Node\n",
    "\n",
    "The planner analyzes the task and creates a step-by-step plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"Structured plan output.\"\"\"\n",
    "    \n",
    "    steps: list[str] = Field(\n",
    "        description=\"List of 3-7 actionable steps to accomplish the task\"\n",
    "    )\n",
    "\n",
    "\n",
    "PLANNER_PROMPT = \"\"\"You are a strategic planner that breaks down complex tasks into clear, actionable steps.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Analyze the task thoroughly\n",
    "2. Create a step-by-step plan with 3-7 concrete steps\n",
    "3. Ensure each step is specific and actionable\n",
    "4. Order steps logically for efficient execution\n",
    "5. Make steps independent where possible\n",
    "\n",
    "Guidelines:\n",
    "- Keep steps simple and focused\n",
    "- Avoid vague or abstract steps\n",
    "- Each step should have a clear completion criterion\n",
    "- Consider dependencies between steps\n",
    "- Aim for the minimum number of steps needed\"\"\"\n",
    "\n",
    "\n",
    "def create_planner_node(llm):\n",
    "    \"\"\"Create a planner that generates step-by-step plans.\"\"\"\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(Plan)\n",
    "    \n",
    "    def planner(state: PlanExecuteState) -> dict:\n",
    "        messages = [\n",
    "            SystemMessage(content=PLANNER_PROMPT),\n",
    "            HumanMessage(content=f\"\"\"Task: {state['task']}\n",
    "\n",
    "Create a detailed step-by-step plan to accomplish this task.\n",
    "Break it into 3-7 clear, actionable steps.\"\"\")\n",
    "        ]\n",
    "        \n",
    "        output = structured_llm.invoke(messages)\n",
    "        steps = output.steps\n",
    "        \n",
    "        print(f\"\\n[Planner] Created plan with {len(steps)} steps:\")\n",
    "        for i, step in enumerate(steps, 1):\n",
    "            print(f\"  {i}. {step}\")\n",
    "        \n",
    "        return {\"plan\": steps, \"current_step\": 0}\n",
    "    \n",
    "    return planner\n",
    "\n",
    "\n",
    "print(\"Planner node creator defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Step 4: Create the Executor Node\n",
    "\n",
    "The executor processes steps one at a time, building on previous results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXECUTOR_PROMPT = \"\"\"You are a task executor working through a plan step by step.\n",
    "\n",
    "Your responsibilities:\n",
    "- Execute the current step thoroughly\n",
    "- Use available tools when needed\n",
    "- Provide clear, specific results\n",
    "- Build on previous step results when relevant\n",
    "\n",
    "Focus on completing your assigned step effectively.\"\"\"\n",
    "\n",
    "\n",
    "def create_executor_node(llm, tools=None):\n",
    "    \"\"\"Create an executor that processes one step at a time.\"\"\"\n",
    "    \n",
    "    # If tools provided, use ReAct agent\n",
    "    if tools:\n",
    "        from langgraph.prebuilt import create_react_agent\n",
    "        react_agent = create_react_agent(llm, tools)\n",
    "        use_tools = True\n",
    "    else:\n",
    "        use_tools = False\n",
    "    \n",
    "    def executor(state: PlanExecuteState) -> dict:\n",
    "        plan = state.get(\"plan\", [])\n",
    "        current_step = state.get(\"current_step\", 0)\n",
    "        past_steps = state.get(\"past_steps\", [])\n",
    "        task = state[\"task\"]\n",
    "        \n",
    "        # Check if we're done\n",
    "        if current_step >= len(plan):\n",
    "            return {}\n",
    "        \n",
    "        step = plan[current_step]\n",
    "        \n",
    "        # Build context from past steps\n",
    "        context_parts = [f\"Original task: {task}\\n\"]\n",
    "        \n",
    "        if past_steps:\n",
    "            context_parts.append(\"Steps completed so far:\")\n",
    "            for i, (prev_step, prev_result) in enumerate(past_steps, 1):\n",
    "                context_parts.append(f\"\\n{i}. {prev_step}\")\n",
    "                result_preview = prev_result[:200] + \"...\" if len(prev_result) > 200 else prev_result\n",
    "                context_parts.append(f\"   Result: {result_preview}\")\n",
    "            context_parts.append(\"\\n\")\n",
    "        \n",
    "        context = \"\".join(context_parts)\n",
    "        \n",
    "        print(f\"\\n[Executor] Step {current_step + 1}/{len(plan)}: {step[:60]}...\")\n",
    "        \n",
    "        # Execute the step\n",
    "        if use_tools:\n",
    "            # Use ReAct agent with tools\n",
    "            agent_input = {\n",
    "                \"messages\": [\n",
    "                    HumanMessage(content=f\"\"\"{context}\n",
    "Now execute this step: {step}\n",
    "\n",
    "Use tools if needed to complete this step thoroughly.\"\"\")\n",
    "                ]\n",
    "            }\n",
    "            agent_result = react_agent.invoke(agent_input)\n",
    "            messages = agent_result.get(\"messages\", [])\n",
    "            if messages:\n",
    "                result = messages[-1].content\n",
    "            else:\n",
    "                result = \"Step executed\"\n",
    "        else:\n",
    "            # Use LLM without tools\n",
    "            messages = [\n",
    "                SystemMessage(content=EXECUTOR_PROMPT),\n",
    "                HumanMessage(content=f\"\"\"{context}\n",
    "Now execute this step: {step}\n",
    "\n",
    "Provide a clear, specific result for this step.\"\"\")\n",
    "            ]\n",
    "            response = llm.invoke(messages)\n",
    "            result = response.content\n",
    "        \n",
    "        print(f\"[Executor] Completed\")\n",
    "        \n",
    "        return {\n",
    "            \"past_steps\": [(step, result)],\n",
    "            \"current_step\": current_step + 1,\n",
    "        }\n",
    "    \n",
    "    return executor\n",
    "\n",
    "\n",
    "print(\"Executor node creator defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Step 5: Create the Replanner Node\n",
    "\n",
    "The replanner reviews completed steps and decides whether to finalize or create a new plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    \"\"\"Final response when task is complete.\"\"\"\n",
    "    \n",
    "    response: str = Field(\n",
    "        description=\"Comprehensive response addressing the original task\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Act(BaseModel):\n",
    "    \"\"\"Action decision - either respond or create new plan.\"\"\"\n",
    "    \n",
    "    action: Union[Response, Plan] = Field(\n",
    "        description=\"Either a final Response or a new Plan for continued execution\"\n",
    "    )\n",
    "\n",
    "\n",
    "REPLANNER_PROMPT = \"\"\"You are a replanner that decides whether to continue with the plan or finalize the response.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Review completed steps and their results\n",
    "2. Determine if the original task is accomplished\n",
    "3. Decide to either:\n",
    "   - Respond with the final answer if the task is complete\n",
    "   - Create a new plan if more work is needed\n",
    "\n",
    "Guidelines:\n",
    "- Only finalize if the task is truly complete\n",
    "- If replanning, create steps that build on what's been done\n",
    "- Be efficient - don't add unnecessary steps\"\"\"\n",
    "\n",
    "\n",
    "def create_replanner_node(llm):\n",
    "    \"\"\"Create a replanner that decides to finalize or create new plan.\"\"\"\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(Act)\n",
    "    \n",
    "    def replanner(state: PlanExecuteState) -> dict:\n",
    "        task = state[\"task\"]\n",
    "        past_steps = state.get(\"past_steps\", [])\n",
    "        \n",
    "        # Format past steps for review\n",
    "        steps_summary = []\n",
    "        for i, (step, result) in enumerate(past_steps, 1):\n",
    "            result_preview = result[:300] + \"...\" if len(result) > 300 else result\n",
    "            steps_summary.append(f\"{i}. {step}\\n   Result: {result_preview}\")\n",
    "        \n",
    "        steps_text = \"\\n\\n\".join(steps_summary)\n",
    "        \n",
    "        print(f\"\\n[Replanner] Reviewing {len(past_steps)} completed steps...\")\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=REPLANNER_PROMPT),\n",
    "            HumanMessage(content=f\"\"\"Original task: {task}\n",
    "\n",
    "Steps completed:\n",
    "{steps_text}\n",
    "\n",
    "Based on these results, decide:\n",
    "1. If the task is complete, provide a final Response synthesizing the results\n",
    "2. If more work is needed, provide a new Plan with additional steps\n",
    "\n",
    "What should we do next?\"\"\")\n",
    "        ]\n",
    "        \n",
    "        output = structured_llm.invoke(messages)\n",
    "        \n",
    "        if isinstance(output.action, Response):\n",
    "            print(\"[Replanner] Task complete, finalizing response\")\n",
    "            return {\"response\": output.action.response}\n",
    "        else:  # New Plan\n",
    "            print(f\"[Replanner] Creating new plan with {len(output.action.steps)} steps\")\n",
    "            return {\n",
    "                \"plan\": output.action.steps,\n",
    "                \"current_step\": 0,\n",
    "            }\n",
    "    \n",
    "    return replanner\n",
    "\n",
    "\n",
    "print(\"Replanner node creator defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Step 6: Define Routing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_after_executor(state: PlanExecuteState) -> str:\n",
    "    \"\"\"Route after executor: continue executing or move to replanner.\"\"\"\n",
    "    current_step = state.get(\"current_step\", 0)\n",
    "    plan = state.get(\"plan\", [])\n",
    "    \n",
    "    if current_step < len(plan):\n",
    "        # More steps to execute\n",
    "        return \"executor\"\n",
    "    else:\n",
    "        # Plan complete, go to replanner\n",
    "        return \"replanner\"\n",
    "\n",
    "\n",
    "def route_after_replanner(state: PlanExecuteState) -> str:\n",
    "    \"\"\"Route after replanner: finalize or continue with new plan.\"\"\"\n",
    "    response = state.get(\"response\", \"\")\n",
    "    \n",
    "    if response:\n",
    "        # Response provided, we're done\n",
    "        return \"END\"\n",
    "    else:\n",
    "        # New plan provided, continue executing\n",
    "        return \"executor\"\n",
    "\n",
    "\n",
    "print(\"Routing logic defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Step 7: Build the Plan-Execute Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Create LLM\n",
    "llm = ChatOllama(\n",
    "    model=config.ollama.model,\n",
    "    base_url=config.ollama.base_url,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Build the graph\n",
    "workflow = StateGraph(PlanExecuteState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"planner\", create_planner_node(llm))\n",
    "workflow.add_node(\"executor\", create_executor_node(llm))\n",
    "workflow.add_node(\"replanner\", create_replanner_node(llm))\n",
    "\n",
    "# Build graph structure\n",
    "workflow.add_edge(START, \"planner\")\n",
    "workflow.add_edge(\"planner\", \"executor\")\n",
    "\n",
    "# After executor: loop or go to replanner\n",
    "workflow.add_conditional_edges(\n",
    "    \"executor\",\n",
    "    route_after_executor,\n",
    "    {\n",
    "        \"executor\": \"executor\",\n",
    "        \"replanner\": \"replanner\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# After replanner: execute new plan or end\n",
    "workflow.add_conditional_edges(\n",
    "    \"replanner\",\n",
    "    route_after_replanner,\n",
    "    {\n",
    "        \"executor\": \"executor\",\n",
    "        \"END\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()\n",
    "\n",
    "print(\"Plan-and-execute graph compiled!\")\n",
    "print(\"\\nGraph flow:\")\n",
    "print(\"  START -> planner -> executor\")\n",
    "print(\"  executor -> executor (loop until plan done)\")\n",
    "print(\"  executor -> replanner (when plan complete)\")\n",
    "print(\"  replanner -> executor (new plan) OR END (response)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Step 8: Visualize the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not render graph: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Step 9: Run the Plan-Execute System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_plan_execute(task: str):\n",
    "    \"\"\"Run a task through the plan-and-execute system.\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"Task: {task}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    initial_state = {\n",
    "        \"task\": task,\n",
    "        \"plan\": [],\n",
    "        \"past_steps\": [],\n",
    "        \"current_step\": 0,\n",
    "        \"response\": \"\",\n",
    "    }\n",
    "    \n",
    "    result = graph.invoke(initial_state)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL RESPONSE\")\n",
    "    print(\"=\"*70)\n",
    "    print(result[\"response\"])\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Executed {len(result['past_steps'])} steps total\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Test with a multi-step reasoning task\n",
    "result = run_plan_execute(\n",
    "    \"\"\"Explain the key benefits of microservices architecture.\n",
    "    Include at least 3 specific advantages and 2 potential challenges.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Step 10: Test with Different Task Types\n",
    "\n",
    "Plan-and-execute excels at different types of complex tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research-style task\n",
    "result2 = run_plan_execute(\n",
    "    \"\"\"Compare and contrast the economic systems of capitalism and socialism.\n",
    "    Analyze their key principles, advantages, and real-world implementations.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creative task with multiple constraints\n",
    "result3 = run_plan_execute(\n",
    "    \"\"\"Write a short story about a robot learning to paint.\n",
    "    The story must:\n",
    "    1. Be exactly 3 paragraphs\n",
    "    2. Include a plot twist\n",
    "    3. End with a meaningful lesson about creativity\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Step 11: Add Tools for Enhanced Execution\n",
    "\n",
    "The executor can use tools via ReAct pattern for tasks requiring external information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_knowledge_base(query: str) -> str:\n",
    "    \"\"\"Search a knowledge base for information.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "    \n",
    "    Returns:\n",
    "        Relevant information from the knowledge base\n",
    "    \"\"\"\n",
    "    # Mock implementation\n",
    "    knowledge = {\n",
    "        \"python\": \"Python is a high-level, interpreted programming language known for readability and simplicity.\",\n",
    "        \"langgraph\": \"LangGraph is a library for building stateful, multi-actor applications with LLMs using graphs.\",\n",
    "        \"agents\": \"Agents are systems that can perceive their environment and take actions to achieve goals.\",\n",
    "    }\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    for key, value in knowledge.items():\n",
    "        if key in query_lower:\n",
    "            return value\n",
    "    \n",
    "    return \"No information found for this query.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression.\n",
    "    \n",
    "    Args:\n",
    "        expression: Mathematical expression to evaluate (e.g., \"2 + 2\", \"10 * 5\")\n",
    "    \n",
    "    Returns:\n",
    "        The result of the calculation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "tools = [search_knowledge_base, calculate]\n",
    "\n",
    "# Create graph with tools\n",
    "workflow_with_tools = StateGraph(PlanExecuteState)\n",
    "workflow_with_tools.add_node(\"planner\", create_planner_node(llm))\n",
    "workflow_with_tools.add_node(\"executor\", create_executor_node(llm, tools=tools))\n",
    "workflow_with_tools.add_node(\"replanner\", create_replanner_node(llm))\n",
    "\n",
    "workflow_with_tools.add_edge(START, \"planner\")\n",
    "workflow_with_tools.add_edge(\"planner\", \"executor\")\n",
    "workflow_with_tools.add_conditional_edges(\n",
    "    \"executor\",\n",
    "    route_after_executor,\n",
    "    {\"executor\": \"executor\", \"replanner\": \"replanner\"},\n",
    ")\n",
    "workflow_with_tools.add_conditional_edges(\n",
    "    \"replanner\",\n",
    "    route_after_replanner,\n",
    "    {\"executor\": \"executor\", \"END\": END},\n",
    ")\n",
    "\n",
    "graph_with_tools = workflow_with_tools.compile()\n",
    "\n",
    "print(\"Graph with tools compiled!\")\n",
    "print(f\"Available tools: {[t.name for t in tools]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with tools\n",
    "def run_with_tools(task: str):\n",
    "    initial_state = {\n",
    "        \"task\": task,\n",
    "        \"plan\": [],\n",
    "        \"past_steps\": [],\n",
    "        \"current_step\": 0,\n",
    "        \"response\": \"\",\n",
    "    }\n",
    "    result = graph_with_tools.invoke(initial_state)\n",
    "    print(\"\\nFinal Response:\")\n",
    "    print(result[\"response\"])\n",
    "    return result\n",
    "\n",
    "\n",
    "result4 = run_with_tools(\n",
    "    \"\"\"First, search for information about LangGraph.\n",
    "    Then calculate how many graphs you could build in 100 hours if each takes 5 hours.\n",
    "    Finally, explain how LangGraph helps in building those graphs efficiently.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Step 12: Using the Built-in Module\n",
    "\n",
    "The `langgraph_ollama_local.patterns` module provides a ready-to-use implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_ollama_local.patterns import (\n",
    "    create_plan_execute_graph,\n",
    "    run_plan_execute_task,\n",
    ")\n",
    "\n",
    "# Create the graph using the module\n",
    "module_graph = create_plan_execute_graph(llm, tools=tools)\n",
    "\n",
    "# Run a task\n",
    "result = run_plan_execute_task(\n",
    "    module_graph,\n",
    "    \"\"\"Analyze the impact of remote work on three areas:\n",
    "    1) Employee productivity\n",
    "    2) Company culture\n",
    "    3) Urban development patterns\"\"\"\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Response:\")\n",
    "print(result[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## Step 13: Complete Code\n",
    "\n",
    "Here's the complete implementation in one cell for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Complete Plan-and-Execute Implementation ===\n",
    "\n",
    "from typing import Annotated, Union\n",
    "from typing_extensions import TypedDict\n",
    "import operator\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langgraph_ollama_local import LocalAgentConfig\n",
    "\n",
    "\n",
    "# === State ===\n",
    "class PlanExecuteState(TypedDict):\n",
    "    task: str\n",
    "    plan: list[str]\n",
    "    past_steps: Annotated[list[tuple[str, str]], operator.add]\n",
    "    current_step: int\n",
    "    response: str\n",
    "\n",
    "\n",
    "# === Structured Outputs ===\n",
    "class Plan(BaseModel):\n",
    "    steps: list[str] = Field(description=\"List of steps\")\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    response: str = Field(description=\"Final response\")\n",
    "\n",
    "\n",
    "class Act(BaseModel):\n",
    "    action: Union[Response, Plan] = Field(description=\"Response or new Plan\")\n",
    "\n",
    "\n",
    "# === Node Creators ===\n",
    "def create_planner(llm):\n",
    "    structured_llm = llm.with_structured_output(Plan)\n",
    "    def planner(state):\n",
    "        output = structured_llm.invoke([\n",
    "            HumanMessage(content=f\"Create 3-7 step plan for: {state['task']}\")\n",
    "        ])\n",
    "        return {\"plan\": output.steps, \"current_step\": 0}\n",
    "    return planner\n",
    "\n",
    "\n",
    "def create_executor(llm):\n",
    "    def executor(state):\n",
    "        if state[\"current_step\"] >= len(state[\"plan\"]):\n",
    "            return {}\n",
    "        step = state[\"plan\"][state[\"current_step\"]]\n",
    "        response = llm.invoke([HumanMessage(content=f\"Execute: {step}\")])\n",
    "        return {\n",
    "            \"past_steps\": [(step, response.content)],\n",
    "            \"current_step\": state[\"current_step\"] + 1,\n",
    "        }\n",
    "    return executor\n",
    "\n",
    "\n",
    "def create_replanner(llm):\n",
    "    structured_llm = llm.with_structured_output(Act)\n",
    "    def replanner(state):\n",
    "        summary = \"\\n\".join([f\"{s}: {r[:100]}\" for s, r in state[\"past_steps\"]])\n",
    "        output = structured_llm.invoke([\n",
    "            HumanMessage(content=f\"Task: {state['task']}\\nCompleted:\\n{summary}\\n\\nRespond or create new plan?\")\n",
    "        ])\n",
    "        if isinstance(output.action, Response):\n",
    "            return {\"response\": output.action.response}\n",
    "        return {\"plan\": output.action.steps, \"current_step\": 0}\n",
    "    return replanner\n",
    "\n",
    "\n",
    "# === Routing ===\n",
    "def route_executor(state):\n",
    "    return \"executor\" if state[\"current_step\"] < len(state[\"plan\"]) else \"replanner\"\n",
    "\n",
    "\n",
    "def route_replanner(state):\n",
    "    return \"END\" if state.get(\"response\") else \"executor\"\n",
    "\n",
    "\n",
    "# === Build Graph ===\n",
    "def build_plan_execute_graph():\n",
    "    config = LocalAgentConfig()\n",
    "    llm = ChatOllama(model=config.ollama.model, base_url=config.ollama.base_url, temperature=0)\n",
    "    \n",
    "    g = StateGraph(PlanExecuteState)\n",
    "    g.add_node(\"planner\", create_planner(llm))\n",
    "    g.add_node(\"executor\", create_executor(llm))\n",
    "    g.add_node(\"replanner\", create_replanner(llm))\n",
    "    \n",
    "    g.add_edge(START, \"planner\")\n",
    "    g.add_edge(\"planner\", \"executor\")\n",
    "    g.add_conditional_edges(\"executor\", route_executor, {\"executor\": \"executor\", \"replanner\": \"replanner\"})\n",
    "    g.add_conditional_edges(\"replanner\", route_replanner, {\"executor\": \"executor\", \"END\": END})\n",
    "    \n",
    "    return g.compile()\n",
    "\n",
    "\n",
    "# === Use ===\n",
    "if __name__ == \"__main__\":\n",
    "    graph = build_plan_execute_graph()\n",
    "    result = graph.invoke({\n",
    "        \"task\": \"Explain quantum computing in simple terms\",\n",
    "        \"plan\": [],\n",
    "        \"past_steps\": [],\n",
    "        \"current_step\": 0,\n",
    "        \"response\": \"\",\n",
    "    })\n",
    "    print(result[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Planner** | Creates step-by-step plan upfront |\n",
    "| **Executor** | Processes steps sequentially with context |\n",
    "| **Replanner** | Adaptively decides to finalize or create new plan |\n",
    "| **past_steps** | Accumulates (step, result) pairs for context |\n",
    "| **Structured Output** | Pydantic models ensure reliable parsing |\n",
    "| **Tool Integration** | Executor can use ReAct pattern with tools |\n",
    "| **Two-Phase** | Separate planning from execution for efficiency |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## When to Use Plan-Execute vs Other Patterns\n",
    "\n",
    "| Pattern | Best For | Planning | Execution | Adaptation |\n",
    "|---------|----------|----------|-----------|------------|\n",
    "| **Plan-Execute** | Multi-step tasks with dependencies | Upfront | Sequential | Replanning after completion |\n",
    "| **ReAct** | Simple tasks, exploratory work | Step-by-step | Interleaved | Continuous |\n",
    "| **ReWOO** | Known workflows, token efficiency | Complete upfront | Parallel | None |\n",
    "| **Reflection** | Quality improvement, iterative refinement | None | Single output | Critique-revise loop |\n",
    "\n",
    "**Choose plan-execute when:**\n",
    "- Task requires multiple coordinated steps\n",
    "- You want visibility into the strategy before execution\n",
    "- Different models for planning vs execution would be beneficial\n",
    "- Task complexity justifies upfront planning overhead\n",
    "\n",
    "**Avoid plan-execute when:**\n",
    "- Task is simple and straightforward\n",
    "- Exploration and discovery are key\n",
    "- Steps can't be determined upfront\n",
    "- Real-time adaptation is more important than planning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## What's Next\n",
    "\n",
    "You've mastered the plan-and-execute pattern! You now know:\n",
    "- How to create step-by-step plans from complex tasks\n",
    "- Execute plans sequentially with context from previous steps\n",
    "- Implement adaptive replanning based on results\n",
    "- Integrate tools for enhanced execution capabilities\n",
    "\n",
    "**Continue with Advanced Reasoning:**\n",
    "- **Tutorial 22**: Reflection - Iterative improvement through critique\n",
    "- **Tutorial 23**: Reflexion - Learning from failures across attempts\n",
    "- **Tutorial 24**: LATS - Monte Carlo Tree Search for agents\n",
    "- **Tutorial 25**: ReWOO - Decoupled planning with parallel execution\n",
    "\n",
    "Each pattern offers unique advantages for different types of complex reasoning tasks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
