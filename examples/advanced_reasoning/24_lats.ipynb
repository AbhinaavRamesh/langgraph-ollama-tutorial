{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 24: LATS (Language Agent Tree Search)\n",
    "\n",
    "This tutorial demonstrates the **LATS (Language Agent Tree Search)** pattern, which applies Monte Carlo Tree Search (MCTS) algorithms to language agents for complex reasoning tasks.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Instead of exploring a single solution path like traditional agents, LATS:\n",
    "- **Explores multiple paths** in parallel using tree search\n",
    "- **Balances exploration vs exploitation** using UCB (Upper Confidence Bound)\n",
    "- **Learns from evaluations** via backpropagation up the tree\n",
    "- **Selects best solution** from all explored paths\n",
    "\n",
    "## MCTS Algorithm\n",
    "\n",
    "LATS follows the classic MCTS cycle:\n",
    "\n",
    "1. **Selection**: Choose best node to expand using UCB\n",
    "2. **Expansion**: Generate N candidate actions from LLM\n",
    "3. **Simulation**: Execute tools and evaluate with reflection\n",
    "4. **Backpropagation**: Update node values up to root\n",
    "\n",
    "```\n",
    "                    [Root]\n",
    "                   v=0.5, n=10\n",
    "                       │\n",
    "         ┌─────────────┼─────────────┐\n",
    "         │             │             │\n",
    "    [Child 1]     [Child 2]     [Child 3]\n",
    "    v=0.7, n=5    v=0.3, n=3    v=0.6, n=2\n",
    "         │                            │\n",
    "    ┌────┼────┐                  ┌───┴───┐\n",
    " [C1.1] [C1.2]                [C3.1] [C3.2]\n",
    "```\n",
    "\n",
    "## When to Use LATS\n",
    "\n",
    "Use LATS when:\n",
    "- Task requires complex multi-step reasoning\n",
    "- Multiple solution paths should be explored\n",
    "- You want to balance trying new approaches vs using what works\n",
    "- Quality matters more than speed\n",
    "\n",
    "**Trade-offs**:\n",
    "- ✅ Explores multiple paths (better solutions)\n",
    "- ✅ Learns which approaches work (via backpropagation)\n",
    "- ✅ Can recover from mistakes (tries alternatives)\n",
    "- ❌ More LLM calls (slower, more expensive)\n",
    "- ❌ Requires complexity limits for local models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "from langgraph_ollama_local.patterns.lats import (\n",
    "    Node,\n",
    "    Reflection,\n",
    "    create_lats_graph,\n",
    "    run_lats_task,\n",
    "    select,\n",
    "    get_best_solution,\n",
    ")\n",
    "\n",
    "# Initialize LLM with temperature for diversity\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2:3b\",\n",
    "    temperature=0.7,  # Higher temp for diverse candidates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding MCTS Components\n",
    "\n",
    "### 1.1 Reflection Model\n",
    "\n",
    "The `Reflection` model provides structured evaluation of each candidate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example reflections\n",
    "good_reflection = Reflection(\n",
    "    reflections=\"Good approach, uses correct tool, but answer incomplete\",\n",
    "    score=7,\n",
    "    found_solution=False,\n",
    ")\n",
    "\n",
    "perfect_reflection = Reflection(\n",
    "    reflections=\"Perfect! Correct reasoning, complete answer with evidence\",\n",
    "    score=10,\n",
    "    found_solution=True,\n",
    ")\n",
    "\n",
    "print(f\"Good reflection score: {good_reflection.score}/10 ({good_reflection.normalized_score})\")\n",
    "print(f\"Perfect reflection score: {perfect_reflection.score}/10 ({perfect_reflection.normalized_score})\")\n",
    "print(f\"Solution found: {perfect_reflection.found_solution}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Node Class\n",
    "\n",
    "The `Node` class represents a state in the search tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Create root node\n",
    "root = Node(messages=[], reflection=None, parent=None)\n",
    "print(f\"Root depth: {root.depth}\")\n",
    "print(f\"Root visits: {root.visits}\")\n",
    "print(f\"Root value: {root.value}\")\n",
    "print(f\"Is terminal: {root.is_terminal}\")\n",
    "\n",
    "# Create child node with reflection\n",
    "child_reflection = Reflection(\n",
    "    reflections=\"Made progress on the task\",\n",
    "    score=6,\n",
    "    found_solution=False,\n",
    ")\n",
    "child = Node(\n",
    "    messages=[AIMessage(content=\"Let me search for information\")],\n",
    "    reflection=child_reflection,\n",
    "    parent=root,\n",
    ")\n",
    "root.children.append(child)\n",
    "\n",
    "print(f\"\\nAfter creating child:\")\n",
    "print(f\"Child depth: {child.depth}\")\n",
    "print(f\"Child visits: {child.visits}\")\n",
    "print(f\"Child value: {child.value}\")\n",
    "print(f\"Root visits (backpropagated): {root.visits}\")\n",
    "print(f\"Root value (backpropagated): {root.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 UCB (Upper Confidence Bound)\n",
    "\n",
    "UCB balances **exploitation** (using what works) vs **exploration** (trying new things):\n",
    "\n",
    "```\n",
    "UCB = avg_reward + exploration_weight * sqrt(ln(parent_visits) / node_visits)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two children with different scores\n",
    "reflection_ok = Reflection(reflections=\"OK approach\", score=5, found_solution=False)\n",
    "reflection_good = Reflection(reflections=\"Good approach\", score=8, found_solution=False)\n",
    "\n",
    "child1 = Node(messages=[AIMessage(content=\"approach 1\")], reflection=reflection_ok, parent=root)\n",
    "child2 = Node(messages=[AIMessage(content=\"approach 2\")], reflection=reflection_good, parent=root)\n",
    "\n",
    "root.children = [child1, child2]\n",
    "\n",
    "# Visit child2 more times\n",
    "child2.backpropagate(0.8)\n",
    "child2.backpropagate(0.7)\n",
    "\n",
    "print(\"Child 1 (lower score, less visited):\")\n",
    "print(f\"  Value: {child1.value:.3f}, Visits: {child1.visits}\")\n",
    "print(f\"  UCB (low exploration): {child1.upper_confidence_bound(0.5):.3f}\")\n",
    "print(f\"  UCB (high exploration): {child1.upper_confidence_bound(2.0):.3f}\")\n",
    "\n",
    "print(\"\\nChild 2 (higher score, more visited):\")\n",
    "print(f\"  Value: {child2.value:.3f}, Visits: {child2.visits}\")\n",
    "print(f\"  UCB (low exploration): {child2.upper_confidence_bound(0.5):.3f}\")\n",
    "print(f\"  UCB (high exploration): {child2.upper_confidence_bound(2.0):.3f}\")\n",
    "\n",
    "print(\"\\nWith high exploration weight, less-visited child1 gets bonus!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Selection Algorithm\n",
    "\n",
    "The `select` function chooses the best leaf node to expand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a deeper tree\n",
    "root2 = Node(messages=[], reflection=None, parent=None)\n",
    "\n",
    "# First level\n",
    "r1 = Reflection(reflections=\"approach A\", score=6, found_solution=False)\n",
    "r2 = Reflection(reflections=\"approach B\", score=7, found_solution=False)\n",
    "child_a = Node(messages=[AIMessage(content=\"A\")], reflection=r1, parent=root2)\n",
    "child_b = Node(messages=[AIMessage(content=\"B\")], reflection=r2, parent=root2)\n",
    "root2.children = [child_a, child_b]\n",
    "\n",
    "# Second level (only under child_b)\n",
    "r3 = Reflection(reflections=\"B.1\", score=8, found_solution=False)\n",
    "child_b1 = Node(messages=[AIMessage(content=\"B.1\")], reflection=r3, parent=child_b)\n",
    "child_b.children = [child_b1]\n",
    "\n",
    "# Select best leaf to expand\n",
    "selected = select(root2)\n",
    "print(f\"Selected node depth: {selected.depth}\")\n",
    "print(f\"Selected node messages: {[m.content for m in selected.messages]}\")\n",
    "print(f\"\\nSelection traversed the tree to find the best leaf!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building a LATS Agent\n",
    "\n",
    "### 2.1 Define Tools\n",
    "\n",
    "Let's create simple tools for a math problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression.\n",
    "    \n",
    "    Args:\n",
    "        expression: Math expression to evaluate (e.g., \"2+2\", \"10*5\")\n",
    "    \n",
    "    Returns:\n",
    "        Result of the calculation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Safe eval for basic math\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "@tool\n",
    "def get_number_info(number: int) -> str:\n",
    "    \"\"\"Get information about a number.\n",
    "    \n",
    "    Args:\n",
    "        number: Number to get info about\n",
    "    \n",
    "    Returns:\n",
    "        Information about the number\n",
    "    \"\"\"\n",
    "    info = []\n",
    "    info.append(f\"Number: {number}\")\n",
    "    info.append(f\"Even: {number % 2 == 0}\")\n",
    "    info.append(f\"Square: {number ** 2}\")\n",
    "    return \"\\n\".join(info)\n",
    "\n",
    "tools = [calculator, get_number_info]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create LATS Graph\n",
    "\n",
    "Create the graph with complexity limits for local models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 3B model, use conservative limits\n",
    "graph = create_lats_graph(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    max_depth=3,           # Limit tree depth\n",
    "    max_width=2,           # 2 candidates per expansion\n",
    "    max_iterations=10,     # Max 10 total nodes\n",
    "    exploration_weight=1.0, # Balanced exploration\n",
    ")\n",
    "\n",
    "print(\"LATS graph created!\")\n",
    "print(f\"Max depth: 3\")\n",
    "print(f\"Max width: 2 candidates per expansion\")\n",
    "print(f\"Max iterations: 10 total nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Run Tree Search\n",
    "\n",
    "Let's solve a problem that benefits from exploring multiple approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"\"\"What is the square of the sum of 15 and 25?\n",
    "Break this down step by step and calculate the final answer.\"\"\"\n",
    "\n",
    "print(f\"Task: {task}\")\n",
    "print(\"\\nRunning LATS tree search...\\n\")\n",
    "\n",
    "result = run_lats_task(graph, task)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SEARCH COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total nodes explored: {result['total_nodes']}\")\n",
    "print(f\"Tree height: {result['root'].height}\")\n",
    "print(f\"Solution found: {result['best_solution'].reflection.found_solution if result['best_solution'].reflection else False}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Inspect the Search Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node: Node, prefix: str = \"\", is_last: bool = True):\n",
    "    \"\"\"Print tree structure.\"\"\"\n",
    "    connector = \"└── \" if is_last else \"├── \"\n",
    "    \n",
    "    # Node info\n",
    "    if node.reflection:\n",
    "        info = f\"score={node.reflection.score}/10, visits={node.visits}, value={node.value:.2f}\"\n",
    "        if node.reflection.found_solution:\n",
    "            info += \" ✓ SOLUTION\"\n",
    "    else:\n",
    "        info = f\"ROOT, visits={node.visits}, value={node.value:.2f}\"\n",
    "    \n",
    "    print(f\"{prefix}{connector}{info}\")\n",
    "    \n",
    "    # Children\n",
    "    extension = \"    \" if is_last else \"│   \"\n",
    "    for i, child in enumerate(node.children):\n",
    "        is_last_child = i == len(node.children) - 1\n",
    "        print_tree(child, prefix + extension, is_last_child)\n",
    "\n",
    "print(\"\\nSearch Tree Structure:\")\n",
    "print(\"=\"*60)\n",
    "print_tree(result['root'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Examine Best Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = result['best_solution']\n",
    "\n",
    "print(\"Best Solution Trajectory:\")\n",
    "print(\"=\"*60)\n",
    "for i, msg in enumerate(result['best_trajectory'], 1):\n",
    "    print(f\"\\nStep {i} ({msg.__class__.__name__}):\")\n",
    "    print(f\"{msg.content}\")\n",
    "\n",
    "if best.reflection:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Reflection:\")\n",
    "    print(f\"Score: {best.reflection.score}/10\")\n",
    "    print(f\"Critique: {best.reflection.reflections}\")\n",
    "    print(f\"Solution found: {best.reflection.found_solution}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Complexity Limits for Local Models\n",
    "\n",
    "### 3.1 Understanding the Trade-offs\n",
    "\n",
    "LATS is computationally expensive. Each expansion:\n",
    "- Generates `max_width` candidates (multiple LLM calls)\n",
    "- Executes tools for each candidate\n",
    "- Reflects on each candidate\n",
    "\n",
    "**Recommended limits by model size:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complexity_limits = {\n",
    "    \"3B-8B\": {\n",
    "        \"max_depth\": 3,\n",
    "        \"max_width\": 2,\n",
    "        \"max_iterations\": 10,\n",
    "        \"timeout\": \"30s\",\n",
    "        \"notes\": \"Conservative limits for small models\",\n",
    "    },\n",
    "    \"13B-34B\": {\n",
    "        \"max_depth\": 4,\n",
    "        \"max_width\": 3,\n",
    "        \"max_iterations\": 20,\n",
    "        \"timeout\": \"45s\",\n",
    "        \"notes\": \"Moderate complexity for medium models\",\n",
    "    },\n",
    "    \"70B+\": {\n",
    "        \"max_depth\": 5,\n",
    "        \"max_width\": 4,\n",
    "        \"max_iterations\": 30,\n",
    "        \"timeout\": \"60s\",\n",
    "        \"notes\": \"Higher complexity for large models\",\n",
    "    },\n",
    "}\n",
    "\n",
    "import json\n",
    "print(json.dumps(complexity_limits, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Creating Graphs for Different Model Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lats_for_model(model_name: str, model_size: str):\n",
    "    \"\"\"Create LATS graph with appropriate limits for model size.\"\"\"\n",
    "    limits = complexity_limits.get(model_size, complexity_limits[\"3B-8B\"])\n",
    "    \n",
    "    llm = ChatOllama(model=model_name, temperature=0.7)\n",
    "    \n",
    "    graph = create_lats_graph(\n",
    "        llm=llm,\n",
    "        tools=tools,\n",
    "        max_depth=limits[\"max_depth\"],\n",
    "        max_width=limits[\"max_width\"],\n",
    "        max_iterations=limits[\"max_iterations\"],\n",
    "    )\n",
    "    \n",
    "    return graph\n",
    "\n",
    "# Example configurations\n",
    "print(\"Example configurations:\")\n",
    "print(\"\\n1. Small model (llama3.2:3b):\")\n",
    "print(\"   graph = create_lats_for_model('llama3.2:3b', '3B-8B')\")\n",
    "print(\"\\n2. Medium model (llama3.1:13b):\")\n",
    "print(\"   graph = create_lats_for_model('llama3.1:13b', '13B-34B')\")\n",
    "print(\"\\n3. Large model (llama3.1:70b):\")\n",
    "print(\"   graph = create_lats_for_model('llama3.1:70b', '70B+')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Advanced Patterns\n",
    "\n",
    "### 4.1 Adjusting Exploration Weight\n",
    "\n",
    "The exploration weight controls UCB behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low exploration (exploit what works)\n",
    "graph_exploit = create_lats_graph(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    max_depth=3,\n",
    "    max_width=2,\n",
    "    exploration_weight=0.3,  # Low - focus on high-scoring paths\n",
    ")\n",
    "\n",
    "# High exploration (try diverse approaches)\n",
    "graph_explore = create_lats_graph(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    max_depth=3,\n",
    "    max_width=2,\n",
    "    exploration_weight=2.0,  # High - try less-visited paths\n",
    ")\n",
    "\n",
    "print(\"Created two graphs with different exploration strategies:\")\n",
    "print(\"1. graph_exploit: exploration_weight=0.3 (focus on best paths)\")\n",
    "print(\"2. graph_explore: exploration_weight=2.0 (try diverse paths)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Custom Reflection Criteria\n",
    "\n",
    "You can implement custom reflection logic by modifying the reflection prompt or using multi-criteria scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Best Practices\n",
    "\n",
    "### 5.1 When to Use LATS\n",
    "\n",
    "✅ **Good use cases:**\n",
    "- Complex reasoning requiring multiple steps\n",
    "- Tasks where exploring alternatives is valuable\n",
    "- Problems with multiple valid approaches\n",
    "- When quality matters more than speed\n",
    "\n",
    "❌ **Avoid LATS when:**\n",
    "- Simple, straightforward tasks\n",
    "- Tight latency requirements\n",
    "- Limited compute resources\n",
    "- Single obvious solution path\n",
    "\n",
    "### 5.2 Complexity Management\n",
    "\n",
    "**Start conservative:**\n",
    "```python\n",
    "graph = create_lats_graph(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    max_depth=2,      # Start small\n",
    "    max_width=2,      # Few candidates\n",
    "    max_iterations=6, # Limited nodes\n",
    ")\n",
    "```\n",
    "\n",
    "**Then increase gradually:**\n",
    "```python\n",
    "# Monitor performance, then increase\n",
    "graph = create_lats_graph(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    max_depth=3,\n",
    "    max_width=3,\n",
    "    max_iterations=15,\n",
    ")\n",
    "```\n",
    "\n",
    "### 5.3 Monitoring Tree Growth\n",
    "\n",
    "Always check tree statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_search(result):\n",
    "    \"\"\"Analyze LATS search results.\"\"\"\n",
    "    root = result['root']\n",
    "    all_nodes = [root] + root._get_all_children()\n",
    "    \n",
    "    terminal_nodes = [n for n in all_nodes if n.is_terminal]\n",
    "    solved_nodes = [n for n in all_nodes if n.reflection and n.reflection.found_solution]\n",
    "    \n",
    "    print(f\"Total nodes: {len(all_nodes)}\")\n",
    "    print(f\"Terminal nodes: {len(terminal_nodes)}\")\n",
    "    print(f\"Solved nodes: {len(solved_nodes)}\")\n",
    "    print(f\"Tree height: {root.height}\")\n",
    "    print(f\"Average node value: {sum(n.value for n in all_nodes) / len(all_nodes):.3f}\")\n",
    "    \n",
    "    if solved_nodes:\n",
    "        print(f\"\\nBest solved node score: {max(n.reflection.score for n in solved_nodes)}/10\")\n",
    "\n",
    "# Example usage\n",
    "print(\"Search Analysis:\")\n",
    "print(\"=\"*60)\n",
    "analyze_search(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **LATS = MCTS for Language Agents**\n",
    "   - Select via UCB\n",
    "   - Expand with multiple candidates\n",
    "   - Simulate with tool execution\n",
    "   - Backpropagate scores\n",
    "\n",
    "2. **Complexity Management is Critical**\n",
    "   - Set limits based on model size\n",
    "   - Monitor tree growth\n",
    "   - Start conservative, increase gradually\n",
    "\n",
    "3. **Trade-offs**\n",
    "   - Better solutions via exploration\n",
    "   - More LLM calls (slower, costlier)\n",
    "   - Best for complex reasoning tasks\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Experiment with different exploration weights\n",
    "- Try LATS on your complex reasoning tasks\n",
    "- Compare with single-path agents (ReAct, ReWOO)\n",
    "- Tune complexity limits for your use case\n",
    "\n",
    "### Related Patterns\n",
    "\n",
    "- **Tutorial 21 (Plan-and-Execute)**: Simpler planning approach\n",
    "- **Tutorial 22 (Reflection)**: Single-path improvement\n",
    "- **Tutorial 23 (Reflexion)**: Multi-attempt learning\n",
    "- **Tutorial 25 (ReWOO)**: Efficient planning alternative"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
