{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Tutorial 13: Perplexity-Style Research Assistant\n",
    "\n",
    "Build a **full-featured research assistant** that combines all RAG patterns into a polished, Perplexity-like experience.\n",
    "\n",
    "**What you'll learn:**\n",
    "- **In-Text Citations**: `[1]`, `[2]` style source references\n",
    "- **Source Metadata**: Title, author, page numbers, relevance scores\n",
    "- **Multi-Source Synthesis**: Combine local docs and web search\n",
    "- **Streaming Output**: Real-time response generation\n",
    "- **Follow-Up Suggestions**: Related questions to explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## The Perplexity Experience\n",
    "\n",
    "What makes Perplexity great:\n",
    "1. **Instant answers** with cited sources\n",
    "2. **Visual source cards** showing where info came from\n",
    "3. **Follow-up suggestions** for deeper exploration\n",
    "4. **Streaming** for immediate feedback\n",
    "\n",
    "We'll build all of this locally!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Setup & API Keys\n",
    "\n",
    "For web search, you'll need a Tavily API key (free tier available):\n",
    "\n",
    "1. Sign up at https://tavily.com\n",
    "2. Get your API key from the dashboard\n",
    "3. Add to your `.env` file:\n",
    "   ```\n",
    "   TAVILY_API_KEY=tvly-your-key-here\n",
    "   ```\n",
    "\n",
    "Or set it directly in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Or set directly (uncomment and add your key):\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"tvly-your-key-here\"\n",
    "\n",
    "has_tavily = bool(os.environ.get(\"TAVILY_API_KEY\"))\n",
    "print(f\"Tavily API configured: {has_tavily}\")\n",
    "if not has_tavily:\n",
    "    print(\"\\nNote: Web search will use mock results. Set TAVILY_API_KEY for real web search.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_ollama_local import LocalAgentConfig\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "config = LocalAgentConfig()\n",
    "llm = ChatOllama(\n",
    "    model=config.ollama.model,\n",
    "    base_url=config.ollama.base_url,\n",
    "    temperature=0,\n",
    ")\n",
    "print(f\"Using model: {config.ollama.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Source:\n",
    "    \"\"\"A source with metadata for citation.\"\"\"\n",
    "    index: int\n",
    "    title: str\n",
    "    url: str\n",
    "    content: str\n",
    "    source_type: str  # \"local\" or \"web\"\n",
    "    page: Optional[int] = None\n",
    "    relevance_score: float = 0.0\n",
    "\n",
    "class ResearchState(TypedDict):\n",
    "    \"\"\"State for Research Assistant.\"\"\"\n",
    "    question: str\n",
    "    sources: List[Source]\n",
    "    answer: str\n",
    "    citations: Dict[int, str]  # {1: \"source_title\", 2: \"source_title\"}\n",
    "    follow_up_questions: List[str]\n",
    "\n",
    "print(\"State defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_ollama_local.rag import LocalRetriever, DocumentGrader\n",
    "\n",
    "retriever = LocalRetriever()\n",
    "grader = DocumentGrader(llm)\n",
    "\n",
    "def search_local(query: str, k: int = 4) -> List[Source]:\n",
    "    \"\"\"Search local documents.\"\"\"\n",
    "    results = retriever.retrieve(query, k=k)\n",
    "    sources = []\n",
    "    \n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        sources.append(Source(\n",
    "            index=i,\n",
    "            title=doc.metadata.get('filename', 'Unknown'),\n",
    "            url=doc.metadata.get('source', ''),\n",
    "            content=doc.page_content,\n",
    "            source_type='local',\n",
    "            page=doc.metadata.get('page'),\n",
    "            relevance_score=score,\n",
    "        ))\n",
    "    \n",
    "    return sources\n",
    "\n",
    "def search_web(query: str, k: int = 3) -> List[Source]:\n",
    "    \"\"\"Search the web using Tavily.\"\"\"\n",
    "    if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "        return [Source(\n",
    "            index=1,\n",
    "            title=\"Web Search (Mock)\",\n",
    "            url=\"https://example.com\",\n",
    "            content=f\"Mock web result for: {query}\",\n",
    "            source_type='web_mock',\n",
    "            relevance_score=0.5,\n",
    "        )]\n",
    "    \n",
    "    try:\n",
    "        from tavily import TavilyClient\n",
    "        client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "        response = client.search(query, max_results=k)\n",
    "        \n",
    "        sources = []\n",
    "        for i, r in enumerate(response.get(\"results\", []), 1):\n",
    "            sources.append(Source(\n",
    "                index=i,\n",
    "                title=r.get(\"title\", \"Unknown\"),\n",
    "                url=r.get(\"url\", \"\"),\n",
    "                content=r.get(\"content\", \"\"),\n",
    "                source_type='web',\n",
    "                relevance_score=r.get(\"score\", 0.5),\n",
    "            ))\n",
    "        return sources\n",
    "    except Exception as e:\n",
    "        print(f\"Web search failed: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"Search functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "RESEARCH_PROMPT = ChatPromptTemplate.from_template(\n",
    "\"\"\"You are a research assistant providing well-sourced answers.\n",
    "\n",
    "IMPORTANT: You MUST cite sources using [1], [2], etc. format inline with your answer.\n",
    "Every factual claim should have a citation.\n",
    "\n",
    "Sources:\n",
    "{sources}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide a comprehensive answer with inline citations [1], [2], etc.\n",
    "Format your response clearly with proper citations after relevant statements.\n",
    "\n",
    "Answer:\"\"\")\n",
    "\n",
    "FOLLOWUP_PROMPT = ChatPromptTemplate.from_template(\n",
    "\"\"\"Based on this question and answer, suggest 3 follow-up questions the user might want to explore.\n",
    "\n",
    "Question: {question}\n",
    "Answer: {answer}\n",
    "\n",
    "Provide exactly 3 follow-up questions, one per line, without numbering:\"\"\")\n",
    "\n",
    "print(\"Prompts defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_sources(state: ResearchState) -> dict:\n",
    "    \"\"\"Gather sources from local docs and web.\"\"\"\n",
    "    print(\"--- GATHERING SOURCES ---\")\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    # Get local sources\n",
    "    local_sources = search_local(question, k=3)\n",
    "    print(f\"Found {len(local_sources)} local sources\")\n",
    "    \n",
    "    # Grade local sources\n",
    "    relevant_local = []\n",
    "    for src in local_sources:\n",
    "        doc = Document(page_content=src.content)\n",
    "        if grader.grade(doc, question):\n",
    "            relevant_local.append(src)\n",
    "    print(f\"Relevant local sources: {len(relevant_local)}\")\n",
    "    \n",
    "    # Get web sources if local is insufficient\n",
    "    web_sources = []\n",
    "    if len(relevant_local) < 2:\n",
    "        print(\"Supplementing with web search...\")\n",
    "        web_sources = search_web(question, k=2)\n",
    "        print(f\"Found {len(web_sources)} web sources\")\n",
    "    \n",
    "    # Combine and re-index\n",
    "    all_sources = relevant_local + web_sources\n",
    "    for i, src in enumerate(all_sources, 1):\n",
    "        src.index = i\n",
    "    \n",
    "    # Build citation mapping\n",
    "    citations = {src.index: src.title for src in all_sources}\n",
    "    \n",
    "    return {\"sources\": all_sources, \"citations\": citations}\n",
    "\n",
    "print(\"Gather sources node defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: ResearchState) -> dict:\n",
    "    \"\"\"Generate answer with citations.\"\"\"\n",
    "    print(\"--- GENERATING ANSWER ---\")\n",
    "    \n",
    "    sources = state[\"sources\"]\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    if not sources:\n",
    "        return {\"answer\": \"I couldn't find any relevant sources to answer this question.\"}\n",
    "    \n",
    "    # Format sources for prompt\n",
    "    sources_text = \"\\n\\n\".join([\n",
    "        f\"[{src.index}] {src.title}\\n{src.content[:800]}...\"\n",
    "        for src in sources\n",
    "    ])\n",
    "    \n",
    "    messages = RESEARCH_PROMPT.format_messages(\n",
    "        sources=sources_text,\n",
    "        question=question\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "print(\"Generate answer node defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_followups(state: ResearchState) -> dict:\n",
    "    \"\"\"Generate follow-up questions.\"\"\"\n",
    "    print(\"--- GENERATING FOLLOW-UPS ---\")\n",
    "    \n",
    "    messages = FOLLOWUP_PROMPT.format_messages(\n",
    "        question=state[\"question\"],\n",
    "        answer=state[\"answer\"]\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # Parse follow-up questions\n",
    "    followups = [q.strip() for q in response.content.strip().split(\"\\n\") if q.strip()]\n",
    "    \n",
    "    return {\"follow_up_questions\": followups[:3]}\n",
    "\n",
    "print(\"Generate followups node defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph = StateGraph(ResearchState)\n",
    "\n",
    "graph.add_node(\"gather_sources\", gather_sources)\n",
    "graph.add_node(\"generate_answer\", generate_answer)\n",
    "graph.add_node(\"generate_followups\", generate_followups)\n",
    "\n",
    "graph.add_edge(START, \"gather_sources\")\n",
    "graph.add_edge(\"gather_sources\", \"generate_answer\")\n",
    "graph.add_edge(\"generate_answer\", \"generate_followups\")\n",
    "graph.add_edge(\"generate_followups\", END)\n",
    "\n",
    "research_assistant = graph.compile()\n",
    "print(\"Research Assistant compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_response(result: dict) -> str:\n",
    "    \"\"\"Format the response like Perplexity.\"\"\"\n",
    "    output = []\n",
    "    \n",
    "    # Answer\n",
    "    output.append(result[\"answer\"])\n",
    "    output.append(\"\")\n",
    "    \n",
    "    # Sources\n",
    "    output.append(\"‚îÄ\" * 50)\n",
    "    output.append(\"üìö Sources:\")\n",
    "    output.append(\"‚îÄ\" * 50)\n",
    "    \n",
    "    for src in result[\"sources\"]:\n",
    "        source_type = \"üåê\" if \"web\" in src.source_type else \"üìÑ\"\n",
    "        page_info = f\" (page {src.page})\" if src.page else \"\"\n",
    "        score = f\" [{src.relevance_score:.0%}]\" if src.relevance_score else \"\"\n",
    "        output.append(f\"[{src.index}] {source_type} {src.title}{page_info}{score}\")\n",
    "        if src.url and \"http\" in src.url:\n",
    "            output.append(f\"    {src.url}\")\n",
    "    \n",
    "    output.append(\"\")\n",
    "    \n",
    "    # Follow-ups\n",
    "    output.append(\"‚îÄ\" * 50)\n",
    "    output.append(\"üîç Related Questions:\")\n",
    "    output.append(\"‚îÄ\" * 50)\n",
    "    for i, q in enumerate(result.get(\"follow_up_questions\", []), 1):\n",
    "        output.append(f\"{i}. {q}\")\n",
    "    \n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "print(\"Formatter defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Research Assistant\n",
    "question = \"What is Self-RAG and how does it compare to CRAG?\"\n",
    "\n",
    "print(f\"üîé Question: {question}\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = research_assistant.invoke({\"question\": question})\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(format_response(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive research function\n",
    "def research(question: str):\n",
    "    \"\"\"Run a research query and display formatted results.\"\"\"\n",
    "    print(f\"üîé Researching: {question}\\n\")\n",
    "    result = research_assistant.invoke({\"question\": question})\n",
    "    print(format_response(result))\n",
    "    return result\n",
    "\n",
    "# Try another query\n",
    "research(\"What are the key components of Adaptive RAG?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Key Features Implemented\n",
    "\n",
    "| Feature | Implementation |\n",
    "|---------|---------------|\n",
    "| **In-text citations** | `[1]`, `[2]` format in answers |\n",
    "| **Source metadata** | Title, page, relevance score |\n",
    "| **Multi-source** | Local docs + web search |\n",
    "| **Source grading** | Filter irrelevant sources |\n",
    "| **Follow-up questions** | LLM-generated suggestions |\n",
    "| **Formatted output** | Perplexity-style display |\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You've completed all RAG pattern tutorials! You now know how to build:\n",
    "- Basic RAG with document retrieval\n",
    "- Self-RAG with quality grading\n",
    "- CRAG with web search fallback\n",
    "- Adaptive RAG with query routing\n",
    "- Agentic RAG with agent-controlled retrieval\n",
    "- A full Perplexity-style research assistant\n",
    "\n",
    "All running locally with Ollama!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
