{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Tutorial 03: Memory & Persistence\n",
    "\n",
    "In this tutorial, you'll learn how to add memory to your LangGraph agents so they can remember previous conversations.\n",
    "\n",
    "**What you'll learn:**\n",
    "- **Checkpointers**: How LangGraph persists state\n",
    "- **Thread IDs**: Maintaining separate conversations\n",
    "- **MemorySaver**: In-memory persistence for development\n",
    "- **SqliteSaver**: File-based persistence for production\n",
    "- **State inspection**: Viewing conversation history\n",
    "\n",
    "By the end, you'll have a chatbot that remembers your conversation across multiple interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## The Memory Problem\n",
    "\n",
    "In Tutorial 01, we built a basic chatbot. But it had a critical limitation:\n",
    "\n",
    "```python\n",
    "# Each call is independent - no memory!\n",
    "result1 = graph.invoke({\"messages\": [(\"user\", \"My name is Alice\")]})\n",
    "result2 = graph.invoke({\"messages\": [(\"user\", \"What's my name?\")]})  # Doesn't know!\n",
    "```\n",
    "\n",
    "Each `invoke()` starts fresh. The graph has no way to remember what happened before.\n",
    "\n",
    "### The Solution: Checkpointers\n",
    "\n",
    "LangGraph solves this with **checkpointers** - components that save the graph state after each step. When you compile a graph with a checkpointer:\n",
    "\n",
    "1. After each node runs, state is saved to the checkpointer\n",
    "2. State is organized by **thread ID** (like a conversation ID)\n",
    "3. Future calls with the same thread ID continue from the saved state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Graph Visualization\n",
    "\n",
    "The graph structure is the same as Tutorial 01, but now with persistence:\n",
    "\n",
    "![Memory Graph](../docs/images/03-memory-graph.png)\n",
    "\n",
    "The key difference is in how we **compile** the graph - we add a checkpointer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Verify connection\n",
    "from langgraph_ollama_local import LocalAgentConfig\n",
    "\n",
    "config = LocalAgentConfig()\n",
    "print(f\"Ollama: {config.ollama.base_url}\")\n",
    "print(f\"Model: {config.ollama.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Step 1: Build a Basic Chatbot (No Memory)\n",
    "\n",
    "First, let's recreate our chatbot from Tutorial 01 to demonstrate the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# State\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(\n",
    "    model=config.ollama.model,\n",
    "    base_url=config.ollama.base_url,\n",
    ")\n",
    "\n",
    "# Node\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Graph WITHOUT checkpointer\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Compile without checkpointer\n",
    "graph_no_memory = graph_builder.compile()\n",
    "\n",
    "print(\"Graph compiled (no memory)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the problem: no memory between calls\n",
    "result1 = graph_no_memory.invoke({\"messages\": [(\"user\", \"My name is Alice.\")]})\n",
    "print(f\"Response 1: {result1['messages'][-1].content}\")\n",
    "print()\n",
    "\n",
    "result2 = graph_no_memory.invoke({\"messages\": [(\"user\", \"What is my name?\")]})\n",
    "print(f\"Response 2: {result2['messages'][-1].content}\")\n",
    "print()\n",
    "print(\"Note: The chatbot doesn't remember your name!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 2: Add MemorySaver\n",
    "\n",
    "Now let's add memory using `MemorySaver`, the simplest checkpointer.\n",
    "\n",
    "`MemorySaver` stores state in memory (Python dictionaries). It's perfect for:\n",
    "- Development and testing\n",
    "- Single-session applications\n",
    "- Learning LangGraph concepts\n",
    "\n",
    "**Limitation**: State is lost when the Python process ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Create a MemorySaver\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Compile the SAME graph with checkpointer\n",
    "graph_with_memory = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"Graph compiled with MemorySaver!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 3: Using Thread IDs\n",
    "\n",
    "When using a checkpointer, you must provide a **thread ID** in the config. This is like a conversation ID that groups related messages.\n",
    "\n",
    "```python\n",
    "config = {\"configurable\": {\"thread_id\": \"my-conversation-1\"}}\n",
    "result = graph.invoke(input, config=config)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread config\n",
    "thread_config = {\"configurable\": {\"thread_id\": \"conversation-1\"}}\n",
    "\n",
    "# First message\n",
    "result1 = graph_with_memory.invoke(\n",
    "    {\"messages\": [(\"user\", \"My name is Alice.\")]},\n",
    "    config=thread_config\n",
    ")\n",
    "print(f\"Response 1: {result1['messages'][-1].content}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second message - same thread\n",
    "result2 = graph_with_memory.invoke(\n",
    "    {\"messages\": [(\"user\", \"What is my name?\")]},\n",
    "    config=thread_config  # Same thread ID!\n",
    ")\n",
    "print(f\"Response 2: {result2['messages'][-1].content}\")\n",
    "print()\n",
    "print(\"The chatbot remembers your name!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Step 4: Inspecting State\n",
    "\n",
    "You can inspect the saved state for any thread using `get_state()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current state of our thread\n",
    "state = graph_with_memory.get_state(thread_config)\n",
    "\n",
    "print(\"Current thread state:\")\n",
    "print(f\"  Thread ID: {thread_config['configurable']['thread_id']}\")\n",
    "print(f\"  Number of messages: {len(state.values['messages'])}\")\n",
    "print()\n",
    "print(\"Messages:\")\n",
    "for i, msg in enumerate(state.values['messages']):\n",
    "    role = msg.type if hasattr(msg, 'type') else 'unknown'\n",
    "    content = msg.content[:100] + '...' if len(msg.content) > 100 else msg.content\n",
    "    print(f\"  {i+1}. [{role}]: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Step 5: Multiple Threads\n",
    "\n",
    "Different thread IDs maintain separate conversation histories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thread 2: A different conversation\n",
    "thread2_config = {\"configurable\": {\"thread_id\": \"conversation-2\"}}\n",
    "\n",
    "result = graph_with_memory.invoke(\n",
    "    {\"messages\": [(\"user\", \"My name is Bob.\")]},\n",
    "    config=thread2_config\n",
    ")\n",
    "print(f\"Thread 2 Response: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: Thread 1 still remembers Alice\n",
    "result = graph_with_memory.invoke(\n",
    "    {\"messages\": [(\"user\", \"Remind me, what's my name?\")]},\n",
    "    config=thread_config  # Back to thread 1\n",
    ")\n",
    "print(f\"Thread 1 Response: {result['messages'][-1].content}\")\n",
    "print()\n",
    "print(\"Each thread maintains its own conversation history!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Step 6: SqliteSaver for Persistent Storage\n",
    "\n",
    "`MemorySaver` is great for development, but data is lost when the process ends.\n",
    "\n",
    "For persistent storage, use `SqliteSaver` which stores checkpoints in a SQLite database file.\n",
    "\n",
    "**Note**: SqliteSaver requires the `langgraph-checkpoint-sqlite` package:\n",
    "```bash\n",
    "pip install langgraph-checkpoint-sqlite\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# Create SQLite connection\n",
    "# Use :memory: for in-memory SQLite (good for demos)\n",
    "# Or use a file path like \"checkpoints.db\" for persistence\n",
    "conn = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "\n",
    "# Create SqliteSaver\n",
    "sqlite_memory = SqliteSaver(conn)\n",
    "\n",
    "# Compile graph with SqliteSaver\n",
    "graph_sqlite = graph_builder.compile(checkpointer=sqlite_memory)\n",
    "\n",
    "print(\"Graph compiled with SqliteSaver!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SqliteSaver\n",
    "sqlite_config = {\"configurable\": {\"thread_id\": \"sqlite-thread-1\"}}\n",
    "\n",
    "result = graph_sqlite.invoke(\n",
    "    {\"messages\": [(\"user\", \"Remember this: The secret code is 42.\")]},\n",
    "    config=sqlite_config\n",
    ")\n",
    "print(f\"Response: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify it remembers\n",
    "result = graph_sqlite.invoke(\n",
    "    {\"messages\": [(\"user\", \"What was the secret code?\")]},\n",
    "    config=sqlite_config\n",
    ")\n",
    "print(f\"Response: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Step 7: File-Based Persistence\n",
    "\n",
    "For true persistence across Python sessions, use a file-based SQLite database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create a persistent database file\n",
    "db_path = Path(\".checkpoints/conversations.db\")\n",
    "db_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "# Connect to file-based SQLite\n",
    "persistent_conn = sqlite3.connect(str(db_path), check_same_thread=False)\n",
    "persistent_memory = SqliteSaver(persistent_conn)\n",
    "\n",
    "# Compile graph\n",
    "graph_persistent = graph_builder.compile(checkpointer=persistent_memory)\n",
    "\n",
    "print(f\"Database file: {db_path.absolute()}\")\n",
    "print(\"This database persists across Python sessions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Complete Code: Chatbot with Memory\n",
    "\n",
    "Here's the complete implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Chatbot with Memory\n",
    "\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph_ollama_local import LocalAgentConfig\n",
    "\n",
    "# === State ===\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# === LLM ===\n",
    "config = LocalAgentConfig()\n",
    "llm = ChatOllama(\n",
    "    model=config.ollama.model,\n",
    "    base_url=config.ollama.base_url,\n",
    ")\n",
    "\n",
    "# === Node ===\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# === Graph ===\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# === Compile with Checkpointer ===\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# === Use It ===\n",
    "def chat(user_input: str, thread_id: str = \"default\"):\n",
    "    \"\"\"Send a message and get a response.\"\"\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    result = graph.invoke({\"messages\": [(\"user\", user_input)]}, config=config)\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "# Test it\n",
    "print(chat(\"Hi! I'm learning LangGraph.\"))\n",
    "print()\n",
    "print(chat(\"What am I learning?\"))  # Remembers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Key Concepts Recap\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Checkpointer** | Component that saves graph state after each step |\n",
    "| **Thread ID** | Identifier for a conversation (groups related messages) |\n",
    "| **MemorySaver** | In-memory checkpointer (lost on restart) |\n",
    "| **SqliteSaver** | SQLite-based checkpointer (persistent) |\n",
    "| **get_state()** | Inspect the current state of a thread |\n",
    "\n",
    "## Checkpointer Comparison\n",
    "\n",
    "| Checkpointer | Persistence | Use Case |\n",
    "|--------------|-------------|----------|\n",
    "| `MemorySaver` | In-memory only | Development, testing |\n",
    "| `SqliteSaver` | File-based | Local applications, demos |\n",
    "| `PostgresSaver` | Database | Production, multi-server |\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "In [Tutorial 04: Human-in-the-Loop](04_human_in_the_loop.ipynb), you'll learn:\n",
    "- Pausing agent execution for human approval\n",
    "- Using `interrupt_before` and `interrupt_after`\n",
    "- Reviewing and modifying agent actions before they execute"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
