{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 19: Map-Reduce Agents\n",
    "\n",
    "In this tutorial, you'll build a **map-reduce pattern** for parallel agent execution with result aggregation.\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to split complex tasks into parallel subtasks\n",
    "- Creating worker agents that process subtasks independently\n",
    "- Implementing fan-out/fan-in patterns for parallel execution\n",
    "- Aggregating results from multiple parallel workers\n",
    "- When to use map-reduce vs sequential processing\n",
    "\n",
    "By the end, you'll have a working map-reduce system that processes tasks in parallel and synthesizes results.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Tutorials 14-16 (Multi-Agent Patterns)\n",
    "- Understanding of parallel execution concepts\n",
    "- Ollama running with a capable model (llama3.1:8b or larger recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Map-Reduce?\n",
    "\n",
    "Map-reduce is ideal for tasks that can be parallelized:\n",
    "\n",
    "1. **Scalability**: Process large workloads by distributing across workers\n",
    "2. **Speed**: Parallel execution is faster than sequential processing\n",
    "3. **Independence**: Subtasks don't depend on each other\n",
    "4. **Aggregation**: Combine results into a coherent final output\n",
    "\n",
    "**Common use cases:**\n",
    "- Document analysis (each worker analyzes a section)\n",
    "- Data processing (each worker processes a chunk)\n",
    "- Multi-perspective analysis (each worker takes a different angle)\n",
    "- Large-scale summarization\n",
    "\n",
    "```\n",
    "                     ┌─────────────────┐\n",
    "                     │     Mapper      │\n",
    "                     │  (Split Task)   │\n",
    "                     └────────┬────────┘\n",
    "                              │\n",
    "          ┌───────────────────┼───────────────────┐\n",
    "          │                   │                   │\n",
    "          ▼                   ▼                   ▼\n",
    "   ┌─────────────┐     ┌─────────────┐     ┌─────────────┐\n",
    "   │  Worker 1   │     │  Worker 2   │     │  Worker 3   │\n",
    "   │  (Parallel) │     │  (Parallel) │     │  (Parallel) │\n",
    "   └──────┬──────┘     └──────┬──────┘     └──────┬──────┘\n",
    "          │                   │                   │\n",
    "          └───────────────────┼───────────────────┘\n",
    "                              │\n",
    "                              ▼\n",
    "                     ┌─────────────────┐\n",
    "                     │    Reducer      │\n",
    "                     │  (Aggregate)    │\n",
    "                     └─────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Verify Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify our setup\n",
    "from langgraph_ollama_local import LocalAgentConfig\n",
    "\n",
    "config = LocalAgentConfig()\n",
    "print(f\"Ollama URL: {config.ollama.base_url}\")\n",
    "print(f\"Model: {config.ollama.model}\")\n",
    "print(\"Setup verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the Map-Reduce State\n",
    "\n",
    "Our state tracks:\n",
    "- The main task\n",
    "- Subtasks created by the mapper\n",
    "- Results from all workers\n",
    "- The final aggregated result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "import operator\n",
    "\n",
    "\n",
    "class MapReduceState(TypedDict):\n",
    "    \"\"\"State schema for map-reduce pattern.\"\"\"\n",
    "    \n",
    "    # Main task to process\n",
    "    task: str\n",
    "    \n",
    "    # List of subtasks (one per worker)\n",
    "    subtasks: list[str]\n",
    "    \n",
    "    # Results from workers - uses operator.add to accumulate\n",
    "    worker_results: Annotated[list[dict], operator.add]\n",
    "    \n",
    "    # Final aggregated result\n",
    "    final_result: str\n",
    "\n",
    "\n",
    "print(\"State defined!\")\n",
    "print(\"\\nKey fields:\")\n",
    "print(\"- subtasks: Created by mapper, one per worker\")\n",
    "print(\"- worker_results: Accumulated outputs using operator.add\")\n",
    "print(\"- final_result: Synthesized by reducer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create the Mapper Node\n",
    "\n",
    "The mapper splits the main task into independent subtasks that can be processed in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "\n",
    "class MapperOutput(BaseModel):\n",
    "    \"\"\"Structured output from mapper.\"\"\"\n",
    "    \n",
    "    subtasks: list[str] = Field(\n",
    "        description=\"List of independent subtasks, one per worker\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"Brief explanation of how the task was split\"\n",
    "    )\n",
    "\n",
    "\n",
    "MAPPER_PROMPT = \"\"\"You are a mapper agent that splits tasks into parallel subtasks.\n",
    "\n",
    "Your job:\n",
    "1. Analyze the main task\n",
    "2. Break it into {num_workers} independent subtasks\n",
    "3. Ensure subtasks don't depend on each other\n",
    "4. Balance workload across subtasks\n",
    "\n",
    "Guidelines:\n",
    "- Create subtasks that can be completed independently\n",
    "- Make each subtask clear and specific\n",
    "- Aim for equal complexity across subtasks\"\"\"\n",
    "\n",
    "\n",
    "def create_mapper_node(llm, num_workers=3):\n",
    "    \"\"\"Create a mapper that splits tasks into subtasks.\"\"\"\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(MapperOutput)\n",
    "    \n",
    "    def mapper(state: MapReduceState) -> dict:\n",
    "        messages = [\n",
    "            SystemMessage(content=MAPPER_PROMPT.format(num_workers=num_workers)),\n",
    "            HumanMessage(content=f\"\"\"Task: {state['task']}\n",
    "\n",
    "Break this into {num_workers} independent subtasks for parallel processing.\"\"\")\n",
    "        ]\n",
    "        \n",
    "        output = structured_llm.invoke(messages)\n",
    "        \n",
    "        # Ensure we have exactly num_workers subtasks\n",
    "        subtasks = output.subtasks[:num_workers]\n",
    "        \n",
    "        print(f\"\\n[Mapper] Created {len(subtasks)} subtasks:\")\n",
    "        for i, subtask in enumerate(subtasks):\n",
    "            print(f\"  {i+1}. {subtask[:80]}...\")\n",
    "        print(f\"\\n[Mapper] Reasoning: {output.reasoning}\")\n",
    "        \n",
    "        return {\"subtasks\": subtasks}\n",
    "    \n",
    "    return mapper\n",
    "\n",
    "\n",
    "print(\"Mapper node creator defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Worker Nodes\n",
    "\n",
    "Workers process subtasks independently and in parallel. Each worker only knows about its own subtask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKER_PROMPT = \"\"\"You are a worker agent processing a subtask.\n",
    "\n",
    "Your responsibilities:\n",
    "- Complete your assigned subtask thoroughly\n",
    "- Work independently without knowledge of other workers\n",
    "- Provide clear, structured output\n",
    "- Focus only on your specific subtask\n",
    "\n",
    "{custom_instructions}\"\"\"\n",
    "\n",
    "\n",
    "def create_worker_node(llm, worker_id, worker_prompt=\"\"):\n",
    "    \"\"\"Create a worker that processes a subtask.\"\"\"\n",
    "    \n",
    "    system_prompt = WORKER_PROMPT.format(\n",
    "        custom_instructions=worker_prompt or \"Do your best work.\"\n",
    "    )\n",
    "    \n",
    "    def worker(state: MapReduceState) -> dict:\n",
    "        subtasks = state.get(\"subtasks\", [])\n",
    "        \n",
    "        # Get this worker's subtask\n",
    "        if worker_id < len(subtasks):\n",
    "            subtask = subtasks[worker_id]\n",
    "        else:\n",
    "            subtask = f\"Process part {worker_id + 1} of: {state['task']}\"\n",
    "        \n",
    "        print(f\"\\n[Worker {worker_id}] Processing: {subtask[:60]}...\")\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=f\"\"\"Main task: {state['task']}\n",
    "\n",
    "Your subtask: {subtask}\n",
    "\n",
    "Complete your subtask and provide results.\"\"\")\n",
    "        ]\n",
    "        \n",
    "        response = llm.invoke(messages)\n",
    "        \n",
    "        print(f\"[Worker {worker_id}] Completed\")\n",
    "        \n",
    "        return {\n",
    "            \"worker_results\": [{\n",
    "                \"worker_id\": worker_id,\n",
    "                \"subtask\": subtask,\n",
    "                \"output\": response.content,\n",
    "            }]\n",
    "        }\n",
    "    \n",
    "    return worker\n",
    "\n",
    "\n",
    "print(\"Worker node creator defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create the Reducer Node\n",
    "\n",
    "The reducer aggregates all worker outputs into a coherent final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReducerOutput(BaseModel):\n",
    "    \"\"\"Structured output from reducer.\"\"\"\n",
    "    \n",
    "    final_result: str = Field(\n",
    "        description=\"Synthesized result combining all worker outputs\"\n",
    "    )\n",
    "    summary: str = Field(\n",
    "        description=\"Brief summary of key findings\"\n",
    "    )\n",
    "\n",
    "\n",
    "REDUCER_PROMPT = \"\"\"You are a reducer agent that synthesizes results from multiple workers.\n",
    "\n",
    "Your job:\n",
    "1. Review all worker outputs\n",
    "2. Identify common themes and patterns\n",
    "3. Resolve any conflicts or inconsistencies\n",
    "4. Synthesize a coherent final result\n",
    "\n",
    "Guidelines:\n",
    "- Include all important points from workers\n",
    "- Remove redundancy while preserving key information\n",
    "- Organize output logically\n",
    "- Provide comprehensive synthesis, not just concatenation\"\"\"\n",
    "\n",
    "\n",
    "def create_reducer_node(llm):\n",
    "    \"\"\"Create a reducer that aggregates worker results.\"\"\"\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(ReducerOutput)\n",
    "    \n",
    "    def reducer(state: MapReduceState) -> dict:\n",
    "        worker_results = state.get(\"worker_results\", [])\n",
    "        \n",
    "        print(f\"\\n[Reducer] Aggregating {len(worker_results)} worker results...\")\n",
    "        \n",
    "        if not worker_results:\n",
    "            return {\"final_result\": \"No results to aggregate.\"}\n",
    "        \n",
    "        # Build context from all workers\n",
    "        worker_sections = []\n",
    "        for result in worker_results:\n",
    "            worker_id = result.get(\"worker_id\", \"?\")\n",
    "            subtask = result.get(\"subtask\", \"\")\n",
    "            output = result.get(\"output\", \"\")\n",
    "            \n",
    "            worker_sections.append(f\"\"\"### Worker {worker_id}\n",
    "**Subtask**: {subtask}\n",
    "**Output**:\n",
    "{output}\"\"\")\n",
    "        \n",
    "        workers_context = \"\\n\\n\".join(worker_sections)\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=REDUCER_PROMPT),\n",
    "            HumanMessage(content=f\"\"\"Original task: {state['task']}\n",
    "\n",
    "Worker results:\n",
    "{workers_context}\n",
    "\n",
    "Synthesize these results into a comprehensive final output.\"\"\")\n",
    "        ]\n",
    "        \n",
    "        output = structured_llm.invoke(messages)\n",
    "        \n",
    "        print(f\"[Reducer] Synthesis complete\")\n",
    "        print(f\"[Reducer] Summary: {output.summary}\")\n",
    "        \n",
    "        return {\"final_result\": output.final_result}\n",
    "    \n",
    "    return reducer\n",
    "\n",
    "\n",
    "print(\"Reducer node creator defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Build the Map-Reduce Graph\n",
    "\n",
    "Now we assemble the complete graph with parallel worker execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Create LLM\n",
    "llm = ChatOllama(\n",
    "    model=config.ollama.model,\n",
    "    base_url=config.ollama.base_url,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "NUM_WORKERS = 3\n",
    "\n",
    "# Build the graph\n",
    "workflow = StateGraph(MapReduceState)\n",
    "\n",
    "# Add mapper\n",
    "workflow.add_node(\"mapper\", create_mapper_node(llm, NUM_WORKERS))\n",
    "\n",
    "# Add workers\n",
    "for i in range(NUM_WORKERS):\n",
    "    workflow.add_node(f\"worker_{i}\", create_worker_node(llm, i))\n",
    "\n",
    "# Add reducer\n",
    "workflow.add_node(\"reducer\", create_reducer_node(llm))\n",
    "\n",
    "# Build graph structure\n",
    "workflow.add_edge(START, \"mapper\")\n",
    "\n",
    "# Mapper fans out to all workers (parallel execution)\n",
    "for i in range(NUM_WORKERS):\n",
    "    workflow.add_edge(\"mapper\", f\"worker_{i}\")\n",
    "\n",
    "# All workers converge to reducer (fan-in)\n",
    "for i in range(NUM_WORKERS):\n",
    "    workflow.add_edge(f\"worker_{i}\", \"reducer\")\n",
    "\n",
    "# Reducer ends the graph\n",
    "workflow.add_edge(\"reducer\", END)\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()\n",
    "\n",
    "print(\"Map-reduce graph compiled!\")\n",
    "print(f\"\\nGraph structure (with {NUM_WORKERS} workers):\")\n",
    "print(\"  START -> mapper\")\n",
    "print(f\"  mapper -> [worker_0 | worker_1 | worker_2] (parallel)\")\n",
    "print(\"  [all workers] -> reducer (fan-in)\")\n",
    "print(\"  reducer -> END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Run the Map-Reduce System\n",
    "\n",
    "Let's test with a document analysis task - a perfect use case for map-reduce!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_map_reduce(task: str):\n",
    "    \"\"\"Run a task through the map-reduce system.\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"Task: {task}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    initial_state = {\n",
    "        \"task\": task,\n",
    "        \"subtasks\": [],\n",
    "        \"worker_results\": [],\n",
    "        \"final_result\": \"\",\n",
    "    }\n",
    "    \n",
    "    result = graph.invoke(initial_state)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL RESULT\")\n",
    "    print(\"=\"*70)\n",
    "    print(result[\"final_result\"])\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Processed {len(result['worker_results'])} subtasks in parallel\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Test with document analysis\n",
    "result = run_map_reduce(\n",
    "    \"\"\"Analyze the key themes and implications of remote work trends:\n",
    "    \n",
    "Remote work has become increasingly prevalent, driven by technological \n",
    "advancements and changing workforce expectations. This shift impacts \n",
    "company culture, productivity, work-life balance, and urban development. \n",
    "Organizations must adapt their management practices, communication tools, \n",
    "and employee engagement strategies.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Try Different Scenarios\n",
    "\n",
    "Map-reduce excels at different types of parallel analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-perspective analysis\n",
    "result2 = run_map_reduce(\n",
    "    \"\"\"Analyze the impact of artificial intelligence on society from \n",
    "    multiple perspectives: economic, ethical, and technological.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing task\n",
    "result3 = run_map_reduce(\n",
    "    \"\"\"Process and summarize the following customer feedback themes:\n",
    "    1) Product quality and features\n",
    "    2) Customer service experience\n",
    "    3) Pricing and value proposition\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Customize Worker Behavior\n",
    "\n",
    "You can give each worker specialized instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build custom graph with specialized workers\n",
    "custom_workflow = StateGraph(MapReduceState)\n",
    "\n",
    "# Specialized worker prompts\n",
    "worker_prompts = [\n",
    "    \"Focus on technical aspects and implementation details.\",\n",
    "    \"Focus on business impact and strategic implications.\",\n",
    "    \"Focus on user experience and human factors.\",\n",
    "]\n",
    "\n",
    "custom_workflow.add_node(\"mapper\", create_mapper_node(llm, NUM_WORKERS))\n",
    "\n",
    "for i in range(NUM_WORKERS):\n",
    "    custom_workflow.add_node(\n",
    "        f\"worker_{i}\", \n",
    "        create_worker_node(llm, i, worker_prompts[i])\n",
    "    )\n",
    "\n",
    "custom_workflow.add_node(\"reducer\", create_reducer_node(llm))\n",
    "\n",
    "# Build structure\n",
    "custom_workflow.add_edge(START, \"mapper\")\n",
    "for i in range(NUM_WORKERS):\n",
    "    custom_workflow.add_edge(\"mapper\", f\"worker_{i}\")\n",
    "    custom_workflow.add_edge(f\"worker_{i}\", \"reducer\")\n",
    "custom_workflow.add_edge(\"reducer\", END)\n",
    "\n",
    "custom_graph = custom_workflow.compile()\n",
    "\n",
    "print(\"Custom graph compiled with specialized workers!\")\n",
    "print(\"\\nWorker specializations:\")\n",
    "for i, prompt in enumerate(worker_prompts):\n",
    "    print(f\"  Worker {i}: {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test custom graph\n",
    "def run_custom_map_reduce(task: str):\n",
    "    initial_state = {\n",
    "        \"task\": task,\n",
    "        \"subtasks\": [],\n",
    "        \"worker_results\": [],\n",
    "        \"final_result\": \"\",\n",
    "    }\n",
    "    return custom_graph.invoke(initial_state)\n",
    "\n",
    "result4 = run_custom_map_reduce(\n",
    "    \"Analyze the adoption of cloud computing in enterprise environments\"\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Result:\")\n",
    "print(result4[\"final_result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Using the Built-in Module\n",
    "\n",
    "The `langgraph_ollama_local.patterns` module provides a ready-to-use implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_ollama_local.patterns import (\n",
    "    create_map_reduce_graph,\n",
    "    run_map_reduce_task,\n",
    ")\n",
    "\n",
    "# Create the graph using the module\n",
    "module_graph = create_map_reduce_graph(\n",
    "    llm,\n",
    "    num_workers=3,\n",
    "    worker_prompt=\"Provide thorough analysis with specific examples.\"\n",
    ")\n",
    "\n",
    "# Run a task\n",
    "result = run_map_reduce_task(\n",
    "    module_graph,\n",
    "    \"Analyze the environmental, economic, and social impacts of renewable energy adoption\"\n",
    ")\n",
    "\n",
    "print(\"Final Result:\")\n",
    "print(result[\"final_result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Code\n",
    "\n",
    "Here's the complete implementation in one cell for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Complete Map-Reduce Implementation ===\n",
    "\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "import operator\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langgraph_ollama_local import LocalAgentConfig\n",
    "\n",
    "\n",
    "# === State ===\n",
    "class MapReduceState(TypedDict):\n",
    "    task: str\n",
    "    subtasks: list[str]\n",
    "    worker_results: Annotated[list[dict], operator.add]\n",
    "    final_result: str\n",
    "\n",
    "\n",
    "# === Structured Outputs ===\n",
    "class MapperOutput(BaseModel):\n",
    "    subtasks: list[str] = Field(description=\"List of subtasks\")\n",
    "    reasoning: str = Field(description=\"Reasoning for split\")\n",
    "\n",
    "\n",
    "class ReducerOutput(BaseModel):\n",
    "    final_result: str = Field(description=\"Synthesized result\")\n",
    "    summary: str = Field(description=\"Brief summary\")\n",
    "\n",
    "\n",
    "# === Node Creators ===\n",
    "def create_mapper(llm, num_workers):\n",
    "    structured_llm = llm.with_structured_output(MapperOutput)\n",
    "    \n",
    "    def mapper(state):\n",
    "        output = structured_llm.invoke([\n",
    "            SystemMessage(content=f\"Split task into {num_workers} subtasks\"),\n",
    "            HumanMessage(content=f\"Task: {state['task']}\")\n",
    "        ])\n",
    "        return {\"subtasks\": output.subtasks[:num_workers]}\n",
    "    return mapper\n",
    "\n",
    "\n",
    "def create_worker(llm, worker_id):\n",
    "    def worker(state):\n",
    "        subtask = state[\"subtasks\"][worker_id] if worker_id < len(state[\"subtasks\"]) else \"Process task\"\n",
    "        response = llm.invoke([\n",
    "            SystemMessage(content=\"Process your assigned subtask\"),\n",
    "            HumanMessage(content=f\"Subtask: {subtask}\")\n",
    "        ])\n",
    "        return {\"worker_results\": [{\"worker_id\": worker_id, \"output\": response.content}]}\n",
    "    return worker\n",
    "\n",
    "\n",
    "def create_reducer(llm):\n",
    "    structured_llm = llm.with_structured_output(ReducerOutput)\n",
    "    \n",
    "    def reducer(state):\n",
    "        results = \"\\n\\n\".join([f\"Worker {r['worker_id']}: {r['output']}\" for r in state[\"worker_results\"]])\n",
    "        output = structured_llm.invoke([\n",
    "            SystemMessage(content=\"Synthesize worker results\"),\n",
    "            HumanMessage(content=f\"Results:\\n{results}\")\n",
    "        ])\n",
    "        return {\"final_result\": output.final_result}\n",
    "    return reducer\n",
    "\n",
    "\n",
    "# === Build Graph ===\n",
    "def build_map_reduce_graph(num_workers=3):\n",
    "    config = LocalAgentConfig()\n",
    "    llm = ChatOllama(model=config.ollama.model, base_url=config.ollama.base_url, temperature=0)\n",
    "    \n",
    "    g = StateGraph(MapReduceState)\n",
    "    g.add_node(\"mapper\", create_mapper(llm, num_workers))\n",
    "    for i in range(num_workers):\n",
    "        g.add_node(f\"worker_{i}\", create_worker(llm, i))\n",
    "    g.add_node(\"reducer\", create_reducer(llm))\n",
    "    \n",
    "    g.add_edge(START, \"mapper\")\n",
    "    for i in range(num_workers):\n",
    "        g.add_edge(\"mapper\", f\"worker_{i}\")\n",
    "        g.add_edge(f\"worker_{i}\", \"reducer\")\n",
    "    g.add_edge(\"reducer\", END)\n",
    "    \n",
    "    return g.compile()\n",
    "\n",
    "\n",
    "# === Use ===\n",
    "if __name__ == \"__main__\":\n",
    "    graph = build_map_reduce_graph(num_workers=3)\n",
    "    result = graph.invoke({\n",
    "        \"task\": \"Analyze the impact of AI on education\",\n",
    "        \"subtasks\": [],\n",
    "        \"worker_results\": [],\n",
    "        \"final_result\": \"\",\n",
    "    })\n",
    "    print(result[\"final_result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Map Phase** | Mapper splits task into independent subtasks |\n",
    "| **Fan-Out** | Task distributed to multiple workers in parallel |\n",
    "| **Worker Independence** | Each worker processes its subtask without coordination |\n",
    "| **Parallel Execution** | Workers run simultaneously for speed |\n",
    "| **Fan-In** | All worker results collected at reducer |\n",
    "| **Reduce Phase** | Reducer synthesizes all outputs into final result |\n",
    "| **Scalability** | Add more workers to handle larger workloads |\n",
    "| **Structured Output** | Pydantic models ensure reliable parsing |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to Use Map-Reduce vs Other Patterns\n",
    "\n",
    "| Pattern | Best For | Parallelization | Coordination |\n",
    "|---------|----------|-----------------|-------------|\n",
    "| **Map-Reduce** | Independent subtasks, large-scale processing | High (parallel workers) | Low (no inter-worker communication) |\n",
    "| **Supervisor** | Sequential tasks needing different skills | Low (sequential) | High (supervisor coordinates) |\n",
    "| **Hierarchical** | Nested team structures, complex organizations | Medium (team-level) | High (multiple supervisors) |\n",
    "| **Subgraphs** | Reusable components, modular systems | Depends on subgraph | Depends on subgraph |\n",
    "\n",
    "**Choose map-reduce when:**\n",
    "- Task can be split into independent parts\n",
    "- Parallel processing improves speed\n",
    "- Workers don't need to coordinate\n",
    "- Final aggregation is straightforward\n",
    "\n",
    "**Avoid map-reduce when:**\n",
    "- Subtasks depend on each other\n",
    "- Sequential processing is required\n",
    "- Coordination between workers is needed\n",
    "- Task doesn't decompose naturally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next\n",
    "\n",
    "You've completed the multi-agent patterns series! You now know:\n",
    "- **Tutorial 14**: Supervisor pattern for coordinating specialists\n",
    "- **Tutorial 15**: Hierarchical teams for nested organizations\n",
    "- **Tutorial 16**: Subgraphs for reusable components\n",
    "- **Tutorial 19**: Map-reduce for parallel execution\n",
    "\n",
    "**Explore more:**\n",
    "- Combine patterns (e.g., hierarchical teams with map-reduce workers)\n",
    "- Add tools to workers for enhanced capabilities\n",
    "- Implement dynamic worker scaling based on task complexity\n",
    "- Add error handling and retry logic for robust systems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
